{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht classificatie 1 - logistic regression\n",
    "\n",
    "Logistische regressie is een bijzonder populaire classificatietechniek. Enerzijds door zijn eenvoud en relatief lage eisen die het stelt in termen van rekenkracht. In veel gevallen is de performantie qua accuracy vergelijkbaar (en soms beter) dan gecompliceerdere algoritmes zoals de support vector machines.\n",
    "Daarnaast heeft logistische regressie het voordeel dat het getrainde model een voorspelling doet in termen van de kans dat de input tot een bepaalde klasse behoort. Uit deze kans kan je afleiden hoe overtuigd het model is van de gemaakte voorspelling.\n",
    "\n",
    "Het is de bedoeling om via enkele classificatieopdrachten inzicht te verkrijgen in:\n",
    "- Correct trainen en het uitvoeren van hyperparameter tuning bij logistische regressie.\n",
    "- Classificaties kunnen uitvoeren via logistische regressie.\n",
    "- Feature engineering uitvoeren.\n",
    "- Interpreteren van de verschillende performance metrics: accuracy, recall, precision, f1-score, ROC.\n",
    "- Kunnen omgaan met niet-gebalanceerde data en het kunnen regelen tussen het aantal false positives en false negatives. \n",
    "- Weten wanneer je te maken hebt met overfitting en underfitting en de juiste bijstellingen kunnen doen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 1: Sensors data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bestand sensors_data_test is een tijdelijke bestand om onze sensorsdata te simuleren\n",
    "Train nu een logic regression model dat op basis van de features een zo goed mogelijke predictie kan doenvan de afstand waar er eenfles is genomen.\n",
    "\n",
    "### Kolom toevoegen\n",
    "\n",
    "\n",
    "### Inlezen van de dataset en vooranalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartitionKey</th>\n",
       "      <th>RowKey</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>RackRow</th>\n",
       "      <th>RackRow@type</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label@type</th>\n",
       "      <th>WeightPre</th>\n",
       "      <th>WeightPre@type</th>\n",
       "      <th>WeightPost</th>\n",
       "      <th>...</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistAvgH@type</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMinL@type</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistMaxL@type</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistAvgL@type</th>\n",
       "      <th>DistTime</th>\n",
       "      <th>DistTime@type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>06e05b50-bcbf-4fad-a713-c19975ef4b42</td>\n",
       "      <td>2022-05-25T13:16:47.9637282Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>3</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>Int32</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>28</td>\n",
       "      <td>Int32</td>\n",
       "      <td>207</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>0cffb11c-0506-4d8d-8cad-7f2d00053380</td>\n",
       "      <td>2022-05-25T13:15:19.5884474Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>Int32</td>\n",
       "      <td>32</td>\n",
       "      <td>Int32</td>\n",
       "      <td>34</td>\n",
       "      <td>Int32</td>\n",
       "      <td>33</td>\n",
       "      <td>Int32</td>\n",
       "      <td>1136</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>11090373-a998-47a1-b8c3-807b4c036d53</td>\n",
       "      <td>2022-05-25T13:17:16.801118Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>6</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Int32</td>\n",
       "      <td>9</td>\n",
       "      <td>Int32</td>\n",
       "      <td>15</td>\n",
       "      <td>Int32</td>\n",
       "      <td>11</td>\n",
       "      <td>Int32</td>\n",
       "      <td>513</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>13f3867e-2b06-43a9-8843-e3f5245cf925</td>\n",
       "      <td>2022-05-25T13:20:12.9485555Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>21</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>30</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>765</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>275027a4-b73f-484f-916b-ba69df4b65c4</td>\n",
       "      <td>2022-05-25T13:21:42.5068964Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>5</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>Int32</td>\n",
       "      <td>12</td>\n",
       "      <td>Int32</td>\n",
       "      <td>16</td>\n",
       "      <td>Int32</td>\n",
       "      <td>14</td>\n",
       "      <td>Int32</td>\n",
       "      <td>1135</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>397b206d-120f-41b2-875d-5aeb20a71121</td>\n",
       "      <td>2022-05-25T13:20:50.1554834Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>24</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Int32</td>\n",
       "      <td>9</td>\n",
       "      <td>Int32</td>\n",
       "      <td>12</td>\n",
       "      <td>Int32</td>\n",
       "      <td>10</td>\n",
       "      <td>Int32</td>\n",
       "      <td>574</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>4a24c5c6-e4f8-4cff-860c-2f8d754e581b</td>\n",
       "      <td>2022-05-25T13:19:04.2714384Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>15</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>393</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>578c8377-49cf-481b-b234-77900570a574</td>\n",
       "      <td>2022-05-25T13:14:52.8453005Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>1</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>Int32</td>\n",
       "      <td>37</td>\n",
       "      <td>Int32</td>\n",
       "      <td>37</td>\n",
       "      <td>Int32</td>\n",
       "      <td>37</td>\n",
       "      <td>Int32</td>\n",
       "      <td>25</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>666f1a7f-25ef-4638-91cb-fd561b596359</td>\n",
       "      <td>2022-05-25T13:21:15.7140073Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>Int32</td>\n",
       "      <td>32</td>\n",
       "      <td>Int32</td>\n",
       "      <td>35</td>\n",
       "      <td>Int32</td>\n",
       "      <td>33</td>\n",
       "      <td>Int32</td>\n",
       "      <td>584</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>712dd309-c888-45d3-8997-234eb473d2d1</td>\n",
       "      <td>2022-05-25T13:19:43.1138419Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>19</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>Int32</td>\n",
       "      <td>39</td>\n",
       "      <td>Int32</td>\n",
       "      <td>41</td>\n",
       "      <td>Int32</td>\n",
       "      <td>40</td>\n",
       "      <td>Int32</td>\n",
       "      <td>766</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PartitionKey                                RowKey  \\\n",
       "0  F0:08:D1:C8:A7:34  06e05b50-bcbf-4fad-a713-c19975ef4b42   \n",
       "1  F0:08:D1:C8:A7:34  0cffb11c-0506-4d8d-8cad-7f2d00053380   \n",
       "2  F0:08:D1:C8:A7:34  11090373-a998-47a1-b8c3-807b4c036d53   \n",
       "3  F0:08:D1:C8:A7:34  13f3867e-2b06-43a9-8843-e3f5245cf925   \n",
       "4  F0:08:D1:C8:A7:34  275027a4-b73f-484f-916b-ba69df4b65c4   \n",
       "5  F0:08:D1:C8:A7:34  397b206d-120f-41b2-875d-5aeb20a71121   \n",
       "6  F0:08:D1:C8:A7:34  4a24c5c6-e4f8-4cff-860c-2f8d754e581b   \n",
       "7  F0:08:D1:C8:A7:34  578c8377-49cf-481b-b234-77900570a574   \n",
       "8  F0:08:D1:C8:A7:34  666f1a7f-25ef-4638-91cb-fd561b596359   \n",
       "9  F0:08:D1:C8:A7:34  712dd309-c888-45d3-8997-234eb473d2d1   \n",
       "\n",
       "                      Timestamp  RackRow RackRow@type  Label Label@type  \\\n",
       "0  2022-05-25T13:16:47.9637282Z        2        Int32      3      Int32   \n",
       "1  2022-05-25T13:15:19.5884474Z        2        Int32      2      Int32   \n",
       "2   2022-05-25T13:17:16.801118Z        2        Int32      6      Int32   \n",
       "3  2022-05-25T13:20:12.9485555Z        2        Int32     21      Int32   \n",
       "4  2022-05-25T13:21:42.5068964Z        2        Int32      5      Int32   \n",
       "5  2022-05-25T13:20:50.1554834Z        2        Int32     24      Int32   \n",
       "6  2022-05-25T13:19:04.2714384Z        2        Int32     15      Int32   \n",
       "7  2022-05-25T13:14:52.8453005Z        2        Int32      1      Int32   \n",
       "8  2022-05-25T13:21:15.7140073Z        2        Int32      2      Int32   \n",
       "9  2022-05-25T13:19:43.1138419Z        2        Int32     19      Int32   \n",
       "\n",
       "   WeightPre WeightPre@type  WeightPost  ... DistAvgH  DistAvgH@type DistMinL  \\\n",
       "0          0          Int32           0  ...       28          Int32       27   \n",
       "1          0          Int32           0  ...       33          Int32       32   \n",
       "2          0          Int32           0  ...        9          Int32        9   \n",
       "3          0          Int32           0  ...       29          Int32       29   \n",
       "4          0          Int32           0  ...       14          Int32       12   \n",
       "5          0          Int32           0  ...       10          Int32        9   \n",
       "6          0          Int32           0  ...       27          Int32       27   \n",
       "7          0          Int32           0  ...       37          Int32       37   \n",
       "8          0          Int32           0  ...       33          Int32       32   \n",
       "9          0          Int32           0  ...       40          Int32       39   \n",
       "\n",
       "   DistMinL@type DistMaxL  DistMaxL@type DistAvgL  DistAvgL@type DistTime  \\\n",
       "0          Int32       29          Int32       28          Int32      207   \n",
       "1          Int32       34          Int32       33          Int32     1136   \n",
       "2          Int32       15          Int32       11          Int32      513   \n",
       "3          Int32       30          Int32       29          Int32      765   \n",
       "4          Int32       16          Int32       14          Int32     1135   \n",
       "5          Int32       12          Int32       10          Int32      574   \n",
       "6          Int32       29          Int32       27          Int32      393   \n",
       "7          Int32       37          Int32       37          Int32       25   \n",
       "8          Int32       35          Int32       33          Int32      584   \n",
       "9          Int32       41          Int32       40          Int32      766   \n",
       "\n",
       "   DistTime@type  \n",
       "0          Int32  \n",
       "1          Int32  \n",
       "2          Int32  \n",
       "3          Int32  \n",
       "4          Int32  \n",
       "5          Int32  \n",
       "6          Int32  \n",
       "7          Int32  \n",
       "8          Int32  \n",
       "9          Int32  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inlezen van de dataset\n",
    "dataset = pd.read_csv('TestData.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controleer of de dataset inconsistenties of foute waarden bevat. Gebruik listwise deletion. Dit betekent dat je alle gegevens van een persoon uit de dataset verwijdert van zodra er 1 feature foutief is of ontbreekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistMinH</th>\n",
       "      <th>DistMaxH</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistTime</th>\n",
       "      <th>RackRow_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>1136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>1135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DistMinH  DistMaxH  DistAvgH  DistMinL  DistMaxL  DistAvgL  DistTime  \\\n",
       "0        27        29        28        27        29        28       207   \n",
       "1        32        34        33        32        34        33      1136   \n",
       "2         9        10         9         9        15        11       513   \n",
       "3        29        30        29        29        30        29       765   \n",
       "4        12        16        14        12        16        14      1135   \n",
       "5         9        12        10         9        12        10       574   \n",
       "6        27        29        27        27        29        27       393   \n",
       "7        37        37        37        37        37        37        25   \n",
       "8        32        35        33        32        35        33       584   \n",
       "9        39        41        40        39        41        40       766   \n",
       "\n",
       "   RackRow_2  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  \n",
       "8          1  \n",
       "9          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# verwijder kollomen die niet relevant zijn met model (id's,types)\n",
    "dataset.drop(['PartitionKey','RowKey','Timestamp',],axis=1,inplace=True)\n",
    "dataset.drop('RackRow@type',axis=1,inplace=True)\n",
    "dataset.drop('Label',axis=1,inplace=True)\n",
    "dataset.drop('Label@type',axis=1,inplace=True)\n",
    "\n",
    "# verwijder kollomen weight \n",
    "dataset.drop(['WeightPre','WeightPre@type','WeightPost','WeightPost@type', 'WeightDiff','WeightDiff@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#verwijder kollomen distance\n",
    "dataset.drop(['DistMinH@type','DistMaxH@type','DistAvgH@type','DistMinL@type', 'DistMaxL@type','DistAvgL@type', 'DistTime@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['RackRow'], prefix='RackRow')],axis=1)\n",
    "dataset.drop(['RackRow'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Countplot DistAvgH')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"DistAvgH\")\n",
    "plt.title('Countplot DistAvgH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domin\\AppData\\Local\\Temp\\ipykernel_28092\\1331905442.py:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "\n",
    "dataset.corr()\n",
    "\n",
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FLES\n",
    "# dataset['Post_groter_dan_pre'] = dataset['WeightPost'].gt(dataset['WeightPre'])\n",
    "# # fles in  op basis vanpost groter dan pre\n",
    "# dataset.insert(0,'Bottle_in',dataset['Post_groter_dan_pre'])\n",
    "# dataset.drop('Post_groter_dan_pre',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# dataset['Pre_groter_dan_post'] = dataset['WeightPre'].gt(dataset['WeightPost'])\n",
    "# #  fles uit op basis van pre  groter dan post\n",
    "# dataset.insert(0,'Bottle_out',dataset['Pre_groter_dan_post'])\n",
    "# dataset.drop('Pre_groter_dan_post',axis=1,inplace=True)\n",
    "\n",
    "# # True en False  van Fles_volomzetten naar 0 en 1:\n",
    "# dataset.Bottle_in.replace({False:0,True:1},inplace=True)\n",
    "\n",
    "# dataset.Bottle_out.replace({False:0,True:1},inplace=True)\n",
    "\n",
    "\n",
    "# #Volle fles in\n",
    "# dataset.insert(0,'Bottle_full',dataset['Bottle_in'])\n",
    "# dataset['Bottle_full'].values[dataset['WeightDiff'] < 2] = 0\n",
    "# dataset['Bottle_full'].values[dataset['WeightDiff'] > 2] = 1\n",
    "\n",
    "# #bottle full in\n",
    "# dataset.insert(0,'Bottle_full_in',dataset['Bottle_in'])\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_in'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_in'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_in'] == 1 ) ] = 0\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_in'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "# #bottle full out\n",
    "# dataset.insert(0,'Bottle_full_out',dataset['Bottle_out'])\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_out'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_out'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_out'] == 1 ) ] = 0\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_out'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "# # #bottle empty in\n",
    "# dataset.insert(0,'Bottle_empty_in',dataset['Bottle_in'])\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_in'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_in'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_in'] == 1 ) ] = 1\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_in'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "#  #bottle empty out\n",
    "# dataset.insert(0,'Bottle_empty_out',dataset['Bottle_out'])\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_out'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_out'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_out'] == 1 ) ] = 1\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_out'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "# #Bottle\n",
    "# dataset.insert(0,'Bottle',0)\n",
    "# dataset['Bottle'].values[dataset['Bottle_full_in'] == 1] = 1\n",
    "# dataset['Bottle'].values[dataset['Bottle_full_out'] == 1] = 2\n",
    "# dataset['Bottle'].values[dataset['Bottle_empty_in'] == 1] = 3\n",
    "# dataset['Bottle'].values[dataset['Bottle_empty_out'] == 1] = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing en opsplitsen van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits de dataset in **features en targets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 7)\n",
      "(29,)\n"
     ]
    }
   ],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['DistAvgH'].values\n",
    "X = dataset.drop(['DistAvgH'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 303 waarden, 13 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CreÃ«er een **trainingset en een testset**. Zorg dat er 100 patiÃ«nten in de testset steken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 7)\n",
      "(10, 7)\n"
     ]
    }
   ],
   "source": [
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schaal de dataset**. Zorg er dus voor dat de features op een gelijke schaalverdeling staan. Voor het scalen kan gebruik gemaakt worden van de *preprocessing.StandardScaler()*. Meer info over het gebruik ervan is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29092512, -0.1606592 , -0.31179979, -0.17375559, -0.26386824,\n",
       "       -0.4816289 ,  0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een logistic regression classifier en testen van het bekomen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een logistic regression classifier op de training data. Kies C=1 als startwaarde. Mocht de dataset niet gebalanceerd zijn (de ene klasse komt frequenter voor dan de andere klasse) dan kan je bij de creatie van het logistic regression model de parameter class_weight='balanced' meegeven. Meer info: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Test het getrainde model op de test set. Bepaal hierbij de confusion matrix, de accuracy en het classification report. Wat zijn de bevindingen? Probeer ook verschillende solvers uit. Bepaal ook telkens de ROC en formuleer conclusies.\n",
    "\n",
    "Probeer de performantie van de classifier te verhogen door de parameter C te veranderen.\n",
    "\n",
    "Evalueer de modellen telkens via de confusion matrix, classification report en indien mogelijk via de ROC-curve. Bespreek de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficiÃ«nten:  [[-4.11126574e-01 -4.83848977e-01 -4.12883285e-01 -3.68818326e-01\n",
      "  -4.22686849e-01  1.29014492e-01  9.09067635e-03]\n",
      " [-1.71991893e-01 -1.60930810e-01 -1.73838822e-01 -1.85744139e-01\n",
      "  -1.96173462e-01  1.05644419e-01  1.95638137e-02]\n",
      " [-3.65153563e-01 -3.68370522e-01 -3.66784564e-01 -3.91070039e-01\n",
      "  -3.64556755e-01  1.25235776e-01 -1.43769379e-02]\n",
      " [-1.16912046e-01 -1.65591421e-01 -1.18936086e-01 -1.11945129e-01\n",
      "  -1.29500744e-01  1.00207371e-01  9.39117214e-03]\n",
      " [ 2.12133421e-03  1.30188502e-02 -6.09660802e-04  5.95048848e-03\n",
      "   9.90625991e-03  7.75938782e-02  7.95877593e-03]\n",
      " [ 1.12197036e-01  1.62807527e-01  1.88424825e-01  1.86368241e-01\n",
      "   1.79237763e-01  1.85677843e-02  1.21386750e-02]\n",
      " [-1.09448857e-01 -1.08440905e-01 -1.11387577e-01 -1.28690474e-01\n",
      "  -1.23571956e-01  9.81635021e-02 -3.70169261e-03]\n",
      " [-1.69979484e-01 -1.91128254e-01 -1.71837369e-01 -1.89021646e-01\n",
      "  -1.68626265e-01  1.05899896e-01 -9.63886788e-03]\n",
      " [ 4.35061228e-02  7.82068139e-02  3.91890630e-02  7.21848342e-02\n",
      "   5.01866127e-02  6.31403901e-02  6.01447739e-03]\n",
      " [ 3.91376106e-01  3.86611366e-01  3.90748308e-01  3.85747325e-01\n",
      "   3.89079095e-01 -5.68361501e-01  1.88633137e-02]\n",
      " [-6.15082276e-02  5.07845805e-02 -6.82993453e-02  3.06283006e-02\n",
      "  -2.15963408e-02  8.39315736e-02  1.41583228e-03]\n",
      " [ 2.20329593e-01  2.37578212e-01  2.11305639e-01  2.33054644e-01\n",
      "   2.27315065e-01 -1.39168572e-02  6.74248526e-03]\n",
      " [ 1.19674576e-02 -4.27196594e-02  9.09285754e-03 -5.61282512e-02\n",
      "  -2.59245802e-02  8.47392201e-02 -5.95281240e-03]\n",
      " [ 1.44761188e-01  1.66869685e-01  1.33557153e-01  1.60011445e-01\n",
      "   1.43324861e-01  2.80581744e-02 -4.54671221e-04]\n",
      " [ 7.72434649e-02 -7.03919832e-02  6.82455673e-02 -9.73110936e-02\n",
      "  -1.94400763e-02  8.44634203e-02 -1.80951851e-02]\n",
      " [ 4.26414824e-01  4.21584863e-01  4.25777858e-01  4.20711849e-01\n",
      "   4.24086967e-01 -7.58535734e-01  8.00461044e-03]\n",
      " [-6.11133452e-02  4.28616514e-02 -6.86751364e-02  2.56945094e-02\n",
      "   1.63975902e-02  8.29126521e-02 -2.06449792e-02]\n",
      " [-2.13439515e-02  1.11722052e-02 -2.52345325e-02 -2.32467569e-03\n",
      "  -1.35774182e-02  8.26658449e-02 -1.44688032e-02]\n",
      " [ 5.86608146e-02  1.99267766e-02  5.21451068e-02  1.07021372e-02\n",
      "   4.61202324e-02  7.05756974e-02 -1.18498827e-02]]\n",
      "intercept: [ 0.00909068  0.01956382 -0.01437694  0.00939117  0.00795878  0.01213868\n",
      " -0.00370169 -0.00963887  0.00601448  0.01886332  0.00141583  0.00674249\n",
      " -0.00595281 -0.00045467 -0.01809519  0.00800461 -0.02064499 -0.01446881\n",
      " -0.01184989]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e4, solver='lbfgs') # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "\n",
    "\n",
    "\n",
    "    # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           9       0.50      1.00      0.67         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.05      0.10      0.07        10\n",
      "weighted avg       0.10      0.20      0.13        10\n",
      "\n",
      "20.0\n",
      "[[2 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\domin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\domin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\domin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\domin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\domin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m probs \u001b[38;5;241m=\u001b[39m logreg\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n\u001b[0;32m      6\u001b[0m preds \u001b[38;5;241m=\u001b[39m probs[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m fpr, tpr, threshold \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mauc(fpr, tpr)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# method I: plt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:962\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[0;32m    874\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    875\u001b[0m ):\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m \n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:731\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    729\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m--> 731\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m    733\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    734\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "CreeÃ«r hogere orde features door gebruik te maken van *preprocessing.PolynomialFeatures*. Meer info is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "Deze functie zal automatische hogere orde features aanmaken door het combineren van de aanwezige features. Heb je bijvoorbeeld drie features, zijnde A, B en C dan worden bij de keuze van een derde orde PolynomialFeatures volgende nieuwe features bijgemaakt:\n",
    "$A^3, B^3,C^3,A^2B,A^2C,AB^2, B^2C,...$\n",
    "\n",
    "Experimenteer met verschillende ordes en gebruik de regularisatieparameter C om de performantie te verhogen. Voor indien nodig ook regularisatie uit via een L1 of L2 penalty.\n",
    "\n",
    "**Opgepast**: het kiezen van een te hoge orde zorgt voor een exponentiÃ«le toename aan features waardoor de logistic regression classifier niet meer binnen aanvaardbare tijd getraind kan worden. Advies is om niet hoger te gaan dan 4de orde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 2\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.0001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.001,tol=0.001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat zijn de bevindingen? Formuleer een conclusie. Bespreek hierin de performantie van de getrainde modellen. Wat is de invloed van de parameter C en van het aantal features? Heb je te maken gehad met underfitting en overfitting en hoe heb je dit bepaald? Welke accuracy werd bekomen en hoe zit het met de Recall en Precision? Is de grootte van de trainingset voldoende?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antwoord: Er was een schommeling van 0.02 bij accuracy afhankelijk van hoe ik de C-waarde wijzigde (C1e5->C1e1), mijn accuracy is 80.0, ook de recall en precision wijzigde mee met de C-waarde (schommeling van 0.1)\n",
    "\n",
    "Bij het toevoegen van hogere orde features heb ik de R2 score bij de trainingsets op 0.96 en 0.99."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspel aan de hand van het getrainde model\n",
    "\n",
    "Voorspel of iemand met onderstaande medische parameters als dan niet hartpatient is. Geef ook de zekerheid van het model weer (kansen dat de patiÃ«nt tot een bepaalde klasse behoort).\n",
    "\n",
    "age: 37 - sex: man, cp:3, trestbps: 140, chol:274, fbs: 1, restecg: 1, thalach: 153, exang: 0, oldpeak: 1.4, \n",
    "slope: 2, ca: 1, thal: 3\n",
    "\n",
    "\n",
    "DistMinH:29\tDistMaxH:30\t\tDistAvgH:X\tDistMinL:29\tDistMaxL:30\tDistAvgL:29\tDistTime:765\tRackRow_2:1\n",
    "\n",
    "\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorspelling van de target.\n",
    "target = np.array([[29,30,29,30,29,765,1]])\n",
    "\n",
    "#scaling\n",
    "scaler.transform(target)\n",
    "\n",
    "print(logreg.predict(target))\n",
    "\n",
    "print(logreg.predict_proba(np.array([29,30,29,30,29,765,1]).reshape(1,-1)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standaard zal het model een sample toewijzen aan klasse 1 van zodra de probiliteit boven de threshold van 50% uisteekt. \n",
    "Men wil echter de kans op false negatives drastisch verminderen door het aanpassen van de threshold. Welke threshold moet men instellen om ervoor te zorgen dat het model op de test set geen false negatives meer voorspelt en toch nog een zo hoog mogelijke accuraatheid heeft?\n",
    "Stel het aantal false negatives in functie van de threshold grafisch voor. Bespreek de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduceren van het aantal false negatives door de threshold aan te passen\n",
    "#threshold verlagen!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 2. Penguins\n",
    "\n",
    "\n",
    "De dataset `penguins.csv` bevat data van verschillende soorten pinguÃ¯ns. Deze dataset is origineel bedoeld om te kijken of het mogelijk is om te voorspellen tot welke soort een pinguÃ¯ns behoort aan de hand van de andere variabelen.\n",
    "\n",
    "<img src='penguins.jpg'>\n",
    "\n",
    "<br />\n",
    "\n",
    "| Variable | Beschrijving |\n",
    "| --- | --- | \n",
    "|studyName \t|De studie waar de data van de penguin oorspronkelijk vandaan komt. |\n",
    "|Sample Number|\tEen unieke ID die iedere penguin die in het onderzoek voorkomt krijgt.\n",
    "|Species |\t De soorten penguins die voorkomen in de dataset.|\n",
    "|Island | Het eiland waar de penguin geobserveerd werd.|\n",
    "|Clutch Completion | Of er minstens 1 eitje uit het nest uitgekomen is.|\n",
    "|Culmen Length (mm) |\tDe lengte van de snavel in millimeter. |\n",
    "|Culmen Depth (mm) | De diepte van de snavel in millimeter. |\n",
    "|Flipper Length (mm)  \t| De lengte van de vin in millimeter. |\n",
    "|Body Mass (g) | Het gewicht van de penguin in gram. |\n",
    "|Sex | Het geslacht (binair: 'FEMALE' - vrouw or 'MALE' - man)|\n",
    "|Comments | Specifieke commentaar die bij een bepaalde penguin hoort.|\n",
    "\n",
    "<br />   \n",
    "lees de dataset in en toon de eerste 7 rijen.  <br />   \n",
    "De kolom comments heeft amper data, deze kolom mag uit de dataset verwijdert worden.  <br />   \n",
    "Gebruik listwise deletion bij de overige ontbrekende waarden. Is de dataset gebalanceerd? Maw, zijn er evenveel penguins per soort?  <br />   \n",
    "Bouw een logistic regression model dat zo accuraat mogelijk de penguinsoort kan bepalen. Hierbij pas je alle overige preprocessing stappen toe die je nodig acht. Het is ook toegestaann om features bij te maken of weg te laten.\n",
    "<br />   \n",
    "Schrijf jouw conclusies op met betrekking tot het finaal bekomen model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sensors_data_test.csv')\n",
    "print('Dimensie van de dataset:',dataset.shape)\n",
    "dataset.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uitwerking van de opdracht: \n",
    "\n",
    "#comments kolom verwijderen\n",
    "dataset.drop('DayTime;;;;',axis=1,inplace=True)\n",
    "\n",
    "dataset.insert(0,'Fles',0)\n",
    "#lege fles\n",
    "dataset['Fles'].values[dataset['WeightDiff'] < 2] = 1\n",
    "#volle fles\n",
    "dataset['Fles'].values[dataset['WeightDiff'] > 2] = 2\n",
    "dataset['Fles'].values[dataset['DistTime'] > 5] = 3\n",
    "dataset['Fles'].values[dataset['DistTime'] < 5] = 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#(rij met) NaN value verwijderen\n",
    "#Inplace=True om wijziging 'op te slaan'\n",
    "dataset.dropna(inplace=True) \n",
    "\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot-encoding toepassen omdat ik strings moet omzetten naar getallen\n",
    "\n",
    "#Species omzetten\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Species'], prefix='Species')],axis=1)\n",
    "dataset.drop(['Species'],axis=1, inplace=True)\n",
    "\n",
    "#Island  omzetten\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Island'], prefix='Island')],axis=1)\n",
    "dataset.drop(['Island'],axis=1, inplace=True)\n",
    "\n",
    "#Clutch completion  omzetten\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Clutch Completion'], prefix='Clutch Completion')],axis=1)\n",
    "dataset.drop(['Clutch Completion'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#Sex/geslacht tabel omzetten\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Sex'], prefix='Sex')],axis=1)\n",
    "dataset.drop(['Sex'],axis=1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"Flipper Length (mm)\")\n",
    "plt.title('Countplot Flipper Length (mm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsporen van ontbrekende waarden\n",
    "\n",
    "missing_values_count = dataset.isnull().sum()\n",
    "print(missing_values_count)\n",
    "msno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "\n",
    "dataset.corr()\n",
    "\n",
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['Flipper Length (mm)'].values\n",
    "X = dataset.drop(['Flipper Length (mm)'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "#1 lijst met 333 waarden, 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "\n",
    "# Om conversion warning te vermijden:\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "\n",
    "\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e3, solver='lbfgs') # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "                                                # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 4\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.1,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2- score op trainingsets: 0.93 en 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 3.  Star Wars\n",
    "\n",
    "Train een logistic regression classifier aan de hand van de dataset 'StarWars.csv') om te voorspellen of iemand al dan niet een Star Wars fan is.\n",
    "Gebruik one-hot encondig waar nodig. Zorg ervoor dat de test set uit minstens 200 samples bestaat.\n",
    "Evalueer de getrainde classifier via de geziene metrics en bespreek de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('StarWars.csv')\n",
    "dataset.head(35)\n",
    "\n",
    "# we merken op dat rij 19 en 24 allemaal nullen bevat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "           square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding! (for loop?)\n",
    "\n",
    "#Have you seen any of the 6 films in the Star Wars franchise? kolom verwijderen en omzetten naar ..yes and ..no\n",
    "\n",
    "#omzetten/features toevoegen\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Have you seen any of the 6 films in the Star Wars franchise?'], prefix='Have you seen any of the 6 films in the Star Wars franchise?')],axis=1)\n",
    "#originele kolom verwijderen\n",
    "dataset.drop(['Have you seen any of the 6 films in the Star Wars franchise?'],axis=1, inplace=True)\n",
    "\n",
    "dataset.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we verwijderen rij 19 en 24  van kolom have you..No omdat ze daar 1 zijn\n",
    "dataset.drop(dataset.loc[dataset['Have you seen any of the 6 films in the Star Wars franchise?_No']==1].index, inplace=True)\n",
    "dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding toepassen op de overige kolommen\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#one-hot encoden van LIJST Features\n",
    "datasets_encode_list = ['Han Solo','Luke Skywalker','Princess Leia Organa','Anakin Skywalker',\n",
    "                        'Obi Wan Kenobi','Emperor Palpatine','Darth Vader','Lando Calrissian',\n",
    "                       'Boba Fett','C-3P0','Jar Jar Binks','Padme Amidala','Yoda',\n",
    "                        'Are you familiar with the Expanded Universe?',\n",
    "                        'Do you consider yourself to be a fan of the Expanded Universe?','Gender','Education',\n",
    "                        'phantom menace seen','attack of the clones seen','revenge of the sith seen','a new hope seen',\n",
    "                        'empire strikes back seen','return of the jedi seen','Location','StarWars fan','R2 D2',\n",
    "                        'Which character shot first?','Age'\n",
    "                       ]\n",
    "\n",
    "oude_datasets = dataset\n",
    "for column in datasets_encode_list:\n",
    "    dataset = pd.concat([dataset,pd.get_dummies(dataset[column],prefix=column)],axis=1)\n",
    "    oude_datasets = dataset.drop([column],axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "# # Han Solo omzetten\n",
    "# dataset = pd.concat([dataset,pd.get_dummies(dataset['Han Solo'], prefix='Han Solo')],axis=1)\n",
    "# #originele kolom verwijderen\n",
    "# dataset.drop(['Han Solo'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"StarWars fan_Yes\")\n",
    "plt.title('StarWars fan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['StarWars fan_Yes'].values\n",
    "X = dataset.drop(['StarWars fan_Yes'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 600 waarden, 130 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen/opdelen in training set en test set (hier minstens 200 training sample)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e2, solver='lbfgs') # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "                                                # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 1\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.0001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.001,tol=0.001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Op beide trainingsets 0.99 en 0.99\n",
    "#AUC = 1.00 wat betekenet dat men perfect de klassen kan onderscheiden\n",
    "#Bij het wijzigen van C-parameter schommeling van ~0.1 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 4. Menselijke activiteit\n",
    "\n",
    "\n",
    "De dataset 'activiteit.csv' bevat meetgegevens die van 30 personen via een smartphone werden afgenomen. Deze meetwaarden zijn onderandere afkomstig van een accelerometer en een gyroscoop die in de smartphone zijn ingebouwd.\n",
    "De bedoeling is om om basis van deze meetwaarden de activiteit van de persoon zo nauwkeurig mogelijk te kunnen inschatten.\n",
    "Er zijn 6 verschillende klasses.\n",
    "\n",
    "\n",
    "Bepaal de 6 verschillende klasses en onderzoek meteen of de dataset gebalanceerd is (gelijkmatige verdeling van de verschillende klasses).\n",
    "Bouw een logistic regression model dat zo accuraat mogelijk de activiteit van de persoon kan bepalen. Hierbij pas je alle nodige preprocessing stappen toe je nodig acht.\n",
    "Het is ook toegestaann om features bij te maken of weg te laten. \n",
    "\n",
    "Schrijf jouw conclusies op met betrekking tot het finaal bekomen model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('activiteit.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking opdracht menselijke activiteit\n",
    "sns.countplot(data=dataset,x='Activity')\n",
    "plt.title('Countplot activity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "\n",
    "#dataset.corr()\n",
    "\n",
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "#f, ax = plt.subplots(figsize=(12, 10))\n",
    "#corr = dataset.corr()\n",
    "#sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "#            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistische kerngetallen\n",
    "#dataset.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot-encoding toepassen omdat ik strings moet omzetten naar getallen\n",
    "\n",
    "#Species omzetten\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Activity'], prefix='Activity')],axis=1)\n",
    "dataset.drop(['Activity'],axis=1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsporen van ontbrekende waarden\n",
    "\n",
    "missing_values_count = dataset.isnull().sum()\n",
    "print(missing_values_count)\n",
    "msno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['Activity_STANDING'].values\n",
    "X = dataset.drop(['Activity_STANDING'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 303 waarden, 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e3, solver='lbfgs') # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "                                                # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 1\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.1,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 score op trainingsets 0.99 en 0.30(?)\n",
    "#Bij het wijzigen van C-parameter enkel verschil van accuracy (~0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
