{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht classificatie 1 - logistic regression\n",
    "\n",
    "Logistische regressie is een bijzonder populaire classificatietechniek. Enerzijds door zijn eenvoud en relatief lage eisen die het stelt in termen van rekenkracht. In veel gevallen is de performantie qua accuracy vergelijkbaar (en soms beter) dan gecompliceerdere algoritmes zoals de support vector machines.\n",
    "Daarnaast heeft logistische regressie het voordeel dat het getrainde model een voorspelling doet in termen van de kans dat de input tot een bepaalde klasse behoort. Uit deze kans kan je afleiden hoe overtuigd het model is van de gemaakte voorspelling.\n",
    "\n",
    "Het is de bedoeling om via enkele classificatieopdrachten inzicht te verkrijgen in:\n",
    "- Correct trainen en het uitvoeren van hyperparameter tuning bij logistische regressie.\n",
    "- Classificaties kunnen uitvoeren via logistische regressie.\n",
    "- Feature engineering uitvoeren.\n",
    "- Interpreteren van de verschillende performance metrics: accuracy, recall, precision, f1-score, ROC.\n",
    "- Kunnen omgaan met niet-gebalanceerde data en het kunnen regelen tussen het aantal false positives en false negatives. \n",
    "- Weten wanneer je te maken hebt met overfitting en underfitting en de juiste bijstellingen kunnen doen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 1: Sensors data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bestand sensors_data_test is een tijdelijke bestand om onze sensorsdata te simuleren\n",
    "Train nu een logic regression model dat op basis van de features een zo goed mogelijke predictie kan doenvan de afstand waar er eenfles is genomen.\n",
    "\n",
    "### Kolom toevoegen\n",
    "\n",
    "\n",
    "### Inlezen van de dataset en vooranalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartitionKey</th>\n",
       "      <th>RowKey</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>RackRow</th>\n",
       "      <th>RackRow@type</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label@type</th>\n",
       "      <th>WeightPre</th>\n",
       "      <th>WeightPre@type</th>\n",
       "      <th>WeightPost</th>\n",
       "      <th>...</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistAvgH@type</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMinL@type</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistMaxL@type</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistAvgL@type</th>\n",
       "      <th>DistTime</th>\n",
       "      <th>DistTime@type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>03674838-7a7d-4f65-a8ff-11315e0d3d10</td>\n",
       "      <td>2022-05-28T13:58:26.3120062Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>21</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>Int32</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>36</td>\n",
       "      <td>Int32</td>\n",
       "      <td>31</td>\n",
       "      <td>Int32</td>\n",
       "      <td>3358</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>0376173d-7059-4211-b4a1-7c168b32ce98</td>\n",
       "      <td>2022-05-28T14:26:33.9141792Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>20</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>Int32</td>\n",
       "      <td>31</td>\n",
       "      <td>Int32</td>\n",
       "      <td>42</td>\n",
       "      <td>Int32</td>\n",
       "      <td>35</td>\n",
       "      <td>Int32</td>\n",
       "      <td>1870</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>0628a786-28da-4c9f-97fc-6ee240e75782</td>\n",
       "      <td>2022-05-28T14:24:57.4637252Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>13</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>Int32</td>\n",
       "      <td>37</td>\n",
       "      <td>Int32</td>\n",
       "      <td>43</td>\n",
       "      <td>Int32</td>\n",
       "      <td>40</td>\n",
       "      <td>Int32</td>\n",
       "      <td>2063</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>062a202a-19cc-4c61-814f-7458a33e04d0</td>\n",
       "      <td>2022-05-28T14:26:42.7918921Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>21</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>Int32</td>\n",
       "      <td>24</td>\n",
       "      <td>Int32</td>\n",
       "      <td>30</td>\n",
       "      <td>Int32</td>\n",
       "      <td>26</td>\n",
       "      <td>Int32</td>\n",
       "      <td>1686</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>06e05b50-bcbf-4fad-a713-c19975ef4b42</td>\n",
       "      <td>2022-05-25T13:16:47.9637282Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>3</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>Int32</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>28</td>\n",
       "      <td>Int32</td>\n",
       "      <td>207</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PartitionKey                                RowKey  \\\n",
       "0  F0:08:D1:C8:A7:34  03674838-7a7d-4f65-a8ff-11315e0d3d10   \n",
       "1  F0:08:D1:C8:A7:34  0376173d-7059-4211-b4a1-7c168b32ce98   \n",
       "2  F0:08:D1:C8:A7:34  0628a786-28da-4c9f-97fc-6ee240e75782   \n",
       "3  F0:08:D1:C8:A7:34  062a202a-19cc-4c61-814f-7458a33e04d0   \n",
       "4  F0:08:D1:C8:A7:34  06e05b50-bcbf-4fad-a713-c19975ef4b42   \n",
       "\n",
       "                      Timestamp  RackRow RackRow@type  Label Label@type  \\\n",
       "0  2022-05-28T13:58:26.3120062Z        2        Int32     21      Int32   \n",
       "1  2022-05-28T14:26:33.9141792Z        2        Int32     20      Int32   \n",
       "2  2022-05-28T14:24:57.4637252Z        2        Int32     13      Int32   \n",
       "3  2022-05-28T14:26:42.7918921Z        2        Int32     21      Int32   \n",
       "4  2022-05-25T13:16:47.9637282Z        2        Int32      3      Int32   \n",
       "\n",
       "   WeightPre WeightPre@type  WeightPost  ... DistAvgH  DistAvgH@type DistMinL  \\\n",
       "0          0          Int32           0  ...       31          Int32       27   \n",
       "1          0          Int32           0  ...       33          Int32       31   \n",
       "2          0          Int32           0  ...       40          Int32       37   \n",
       "3          0          Int32           0  ...       26          Int32       24   \n",
       "4          0          Int32           0  ...       28          Int32       27   \n",
       "\n",
       "   DistMinL@type DistMaxL  DistMaxL@type DistAvgL  DistAvgL@type DistTime  \\\n",
       "0          Int32       36          Int32       31          Int32     3358   \n",
       "1          Int32       42          Int32       35          Int32     1870   \n",
       "2          Int32       43          Int32       40          Int32     2063   \n",
       "3          Int32       30          Int32       26          Int32     1686   \n",
       "4          Int32       29          Int32       28          Int32      207   \n",
       "\n",
       "   DistTime@type  \n",
       "0          Int32  \n",
       "1          Int32  \n",
       "2          Int32  \n",
       "3          Int32  \n",
       "4          Int32  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inlezen van de dataset\n",
    "dataset = pd.read_csv('TestData2.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controleer of de dataset inconsistenties of foute waarden bevat. Gebruik listwise deletion. Dit betekent dat je alle gegevens van een persoon uit de dataset verwijdert van zodra er 1 feature foutief is of ontbreekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>DistMinH</th>\n",
       "      <th>DistMaxH</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>2422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  DistMinH  DistMaxH  DistAvgH  DistMinL  DistMaxL  DistAvgL  \\\n",
       "0       21        27        36        31        27        36        31   \n",
       "1       20        31        37        33        31        42        35   \n",
       "2       13        38        43        40        37        43        40   \n",
       "3       21        24        30        26        24        30        26   \n",
       "4        3        27        29        28        27        29        28   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "145     16        16        17        16        16        17        16   \n",
       "146     22        23        23        23        23        23        23   \n",
       "147      9        28        30        29        28        30        29   \n",
       "148      5        13        16        14        13        16        14   \n",
       "149     23         9        13        10         9        11        10   \n",
       "\n",
       "     DistTime  \n",
       "0        3358  \n",
       "1        1870  \n",
       "2        2063  \n",
       "3        1686  \n",
       "4         207  \n",
       "..        ...  \n",
       "145      2422  \n",
       "146        22  \n",
       "147      1502  \n",
       "148      2069  \n",
       "149      2782  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# verwijder kollomen die niet relevant zijn met model (id's,types)\n",
    "dataset.drop(['PartitionKey','Timestamp','RackRow','RowKey'],axis=1,inplace=True)\n",
    "dataset.drop('RackRow@type',axis=1,inplace=True)\n",
    "# dataset.drop('Label',axis=1,inplace=True)\n",
    "dataset.drop('Label@type',axis=1,inplace=True)\n",
    "\n",
    "# verwijder kollomen weight \n",
    "dataset.drop(['WeightPre','WeightPre@type','WeightPost','WeightPost@type', 'WeightDiff','WeightDiff@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#verwijder kollomen distance\n",
    "dataset.drop(['DistMinH@type','DistMaxH@type','DistAvgH@type','DistMinL@type', 'DistMaxL@type','DistAvgL@type', 'DistTime@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "# dataset = pd.concat([dataset,pd.get_dummies(dataset['RowKey'], prefix='RowKey')],axis=1)\n",
    "# dataset.drop(['RowKey'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side_crate</th>\n",
       "      <th>Label</th>\n",
       "      <th>DistMinH</th>\n",
       "      <th>DistMaxH</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>2601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   side_crate  Label  DistMinH  DistMaxH  DistAvgH  DistMinL  DistMaxL  \\\n",
       "0           0     21        27        36        31        27        36   \n",
       "1           0     20        31        37        33        31        42   \n",
       "2           0     13        38        43        40        37        43   \n",
       "3           0     21        24        30        26        24        30   \n",
       "4           0      3        27        29        28        27        29   \n",
       "5           1      6         4         8         4         4         8   \n",
       "6           1      4        21        24        21        21        26   \n",
       "7           0     13        33        43        39        33        43   \n",
       "8           1     10        22        24        23        23        24   \n",
       "9           1      4        15        17        15        15        17   \n",
       "\n",
       "   DistAvgL  DistTime  \n",
       "0        31      3358  \n",
       "1        35      1870  \n",
       "2        40      2063  \n",
       "3        26      1686  \n",
       "4        28       207  \n",
       "5         4      2406  \n",
       "6        23      2601  \n",
       "7        39      2809  \n",
       "8        23      1877  \n",
       "9        15      1680  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Toevoegen van 'leftside_crate' kolom op basis van labels (1-3,7-9,13-15,19-21)\n",
    "dataset.insert(0,'side_crate', dataset['Label'])\n",
    "#dataset.insert(0,'rightside_crate', dataset['Label'])\n",
    "\n",
    "# leftside_crate waarden links is 0, rechts is 1\n",
    "dataset['side_crate'].values[dataset['Label'] <=24] = 1\n",
    "dataset['side_crate'].values[dataset['Label'] <=21] = 0\n",
    "dataset['side_crate'].values[dataset['Label'] <= 18] = 1\n",
    "dataset['side_crate'].values[dataset['Label'] <= 15] = 0\n",
    "dataset['side_crate'].values[dataset['Label'] <= 12] = 1\n",
    "dataset['side_crate'].values[dataset['Label'] <= 9] = 0\n",
    "dataset['side_crate'].values[dataset['Label'] <= 6] = 1\n",
    "dataset['side_crate'].values[dataset['Label'] <= 3] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'leftside_crate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# gebalanceerdheid controleren\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleftside_crate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountplot leftside_crate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass the following variable\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mkeyword arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:3598\u001b[0m, in \u001b[0;36mcountplot\u001b[1;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, dodge, ax, **kwargs)\u001b[0m\n\u001b[0;32m   3595\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass values for both `x` and `y`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3598\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_CountPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3601\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3602\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\n\u001b[0;32m   3603\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3605\u001b[0m plotter\u001b[38;5;241m.\u001b[39mvalue_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:1584\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[0;32m   1580\u001b[0m              estimator, ci, n_boot, units, seed,\n\u001b[0;32m   1581\u001b[0m              orient, color, palette, saturation, errcolor,\n\u001b[0;32m   1582\u001b[0m              errwidth, capsize, dodge):\n\u001b[0;32m   1583\u001b[0m     \u001b[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1584\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m                             \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[0;32m   1587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_statistic(estimator, ci, n_boot, seed)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:153\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(var, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    152\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret input \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(var)\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Figure out the plotting orientation\u001b[39;00m\n\u001b[0;32m    156\u001b[0m orient \u001b[38;5;241m=\u001b[39m infer_orient(\n\u001b[0;32m    157\u001b[0m     x, y, orient, require_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_numeric\n\u001b[0;32m    158\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret input 'leftside_crate'"
     ]
    }
   ],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"side_crate\")\n",
    "plt.title('Countplot side_crate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "\n",
    "dataset.corr()\n",
    "\n",
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FLES\n",
    "# dataset['Post_groter_dan_pre'] = dataset['WeightPost'].gt(dataset['WeightPre'])\n",
    "# # fles in  op basis vanpost groter dan pre\n",
    "# dataset.insert(0,'Bottle_in',dataset['Post_groter_dan_pre'])\n",
    "# dataset.drop('Post_groter_dan_pre',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# dataset['Pre_groter_dan_post'] = dataset['WeightPre'].gt(dataset['WeightPost'])\n",
    "# #  fles uit op basis van pre  groter dan post\n",
    "# dataset.insert(0,'Bottle_out',dataset['Pre_groter_dan_post'])\n",
    "# dataset.drop('Pre_groter_dan_post',axis=1,inplace=True)\n",
    "\n",
    "# # True en False  van Fles_volomzetten naar 0 en 1:\n",
    "# dataset.Bottle_in.replace({False:0,True:1},inplace=True)\n",
    "\n",
    "# dataset.Bottle_out.replace({False:0,True:1},inplace=True)\n",
    "\n",
    "\n",
    "# #Volle fles in\n",
    "# dataset.insert(0,'Bottle_full',dataset['Bottle_in'])\n",
    "# dataset['Bottle_full'].values[dataset['WeightDiff'] < 2] = 0\n",
    "# dataset['Bottle_full'].values[dataset['WeightDiff'] > 2] = 1\n",
    "\n",
    "# #bottle full in\n",
    "# dataset.insert(0,'Bottle_full_in',dataset['Bottle_in'])\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_in'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_in'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_in'] == 1 ) ] = 0\n",
    "# dataset['Bottle_full_in'].values[dataset['Bottle_in'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "# #bottle full out\n",
    "# dataset.insert(0,'Bottle_full_out',dataset['Bottle_out'])\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_out'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_out'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 1\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_out'] == 1 ) ] = 0\n",
    "# dataset['Bottle_full_out'].values[dataset['Bottle_out'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "# # #bottle empty in\n",
    "# dataset.insert(0,'Bottle_empty_in',dataset['Bottle_in'])\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_in'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_in'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_in'] == 1 ) ] = 1\n",
    "# dataset['Bottle_empty_in'].values[dataset['Bottle_in'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "#  #bottle empty out\n",
    "# dataset.insert(0,'Bottle_empty_out',dataset['Bottle_out'])\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_full'] == 1 & (dataset['Bottle_out'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_out'] == 1 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_full'] == 0 & (dataset['Bottle_out'] == 1 ) ] = 1\n",
    "# dataset['Bottle_empty_out'].values[dataset['Bottle_out'] == 0 & (dataset['Bottle_full'] == 1 ) ] = 0\n",
    "\n",
    "# #Bottle\n",
    "# dataset.insert(0,'Bottle',0)\n",
    "# dataset['Bottle'].values[dataset['Bottle_full_in'] == 1] = 1\n",
    "# dataset['Bottle'].values[dataset['Bottle_full_out'] == 1] = 2\n",
    "# dataset['Bottle'].values[dataset['Bottle_empty_in'] == 1] = 3\n",
    "# dataset['Bottle'].values[dataset['Bottle_empty_out'] == 1] = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing en opsplitsen van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits de dataset in **features en targets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['side_crate'].values\n",
    "X = dataset.drop(['side_crate'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 150 waarden, 7 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CreÃ«er een **trainingset en een testset**. Zorg dat er 100 patiÃ«nten in de testset steken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schaal de dataset**. Zorg er dus voor dat de features op een gelijke schaalverdeling staan. Voor het scalen kan gebruik gemaakt worden van de *preprocessing.StandardScaler()*. Meer info over het gebruik ervan is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een logistic regression classifier en testen van het bekomen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een logistic regression classifier op de training data. Kies C=1 als startwaarde. Mocht de dataset niet gebalanceerd zijn (de ene klasse komt frequenter voor dan de andere klasse) dan kan je bij de creatie van het logistic regression model de parameter class_weight='balanced' meegeven. Meer info: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Test het getrainde model op de test set. Bepaal hierbij de confusion matrix, de accuracy en het classification report. Wat zijn de bevindingen? Probeer ook verschillende solvers uit. Bepaal ook telkens de ROC en formuleer conclusies.\n",
    "\n",
    "Probeer de performantie van de classifier te verhogen door de parameter C te veranderen.\n",
    "\n",
    "Evalueer de modellen telkens via de confusion matrix, classification report en indien mogelijk via de ROC-curve. Bespreek de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e4, solver='lbfgs', max_iter=10000 ) # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "\n",
    "\n",
    "\n",
    "    # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "CreeÃ«r hogere orde features door gebruik te maken van *preprocessing.PolynomialFeatures*. Meer info is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "Deze functie zal automatische hogere orde features aanmaken door het combineren van de aanwezige features. Heb je bijvoorbeeld drie features, zijnde A, B en C dan worden bij de keuze van een derde orde PolynomialFeatures volgende nieuwe features bijgemaakt:\n",
    "$A^3, B^3,C^3,A^2B,A^2C,AB^2, B^2C,...$\n",
    "\n",
    "Experimenteer met verschillende ordes en gebruik de regularisatieparameter C om de performantie te verhogen. Voor indien nodig ook regularisatie uit via een L1 of L2 penalty.\n",
    "\n",
    "**Opgepast**: het kiezen van een te hoge orde zorgt voor een exponentiÃ«le toename aan features waardoor de logistic regression classifier niet meer binnen aanvaardbare tijd getraind kan worden. Advies is om niet hoger te gaan dan 4de orde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 3\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.0001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.001,tol=0.001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 trainingsscore 0.83 en 0.88 (graad 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat zijn de bevindingen? Formuleer een conclusie. Bespreek hierin de performantie van de getrainde modellen. Wat is de invloed van de parameter C en van het aantal features? Heb je te maken gehad met underfitting en overfitting en hoe heb je dit bepaald? Welke accuracy werd bekomen en hoe zit het met de Recall en Precision? Is de grootte van de trainingset voldoende?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antwoord: Er was een schommeling van 0.02 bij accuracy afhankelijk van hoe ik de C-waarde wijzigde (C1e5->C1e1), mijn accuracy is 80.0, ook de recall en precision wijzigde mee met de C-waarde (schommeling van 0.1)\n",
    "\n",
    "Bij het toevoegen van hogere orde features heb ik de R2 score bij de trainingsets op 0.96 en 0.99."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspel aan de hand van het getrainde model\n",
    "\n",
    "Voorspel of linker kant van krat of niet. Geef ook de zekerheid van het model weer (kansen dat de fles/hand tot een bepaalde klasse behoort).\n",
    "\n",
    "\n",
    "\n",
    "(leftside_crate) Label\tDistMinH\tDistMaxH\tDistAvgH\tDistMinL\tDistMaxL\tDistAvgL\tDistTime\n",
    "\n",
    "1\t21\t27\t36\t31\t27\t36\t31\t3358\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorspelling van de DistAvgL.\n",
    "DistAvgL = np.array([[21,27,36,31,27,36,31,3358]])\n",
    "\n",
    "#scaling\n",
    "scaler.transform(DistAvgL)\n",
    "\n",
    "print(logreg.predict(DistAvgL))\n",
    "\n",
    "print(logreg.predict_proba(np.array([21,27,36,31,27,36,31,3358]).reshape(1,-1)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standaard zal het model een sample toewijzen aan klasse 1 van zodra de probiliteit boven de threshold van 50% uisteekt. \n",
    "Men wil echter de kans op false negatives drastisch verminderen door het aanpassen van de threshold. Welke threshold moet men instellen om ervoor te zorgen dat het model op de test set geen false negatives meer voorspelt en toch nog een zo hoog mogelijke accuraatheid heeft?\n",
    "Stel het aantal false negatives in functie van de threshold grafisch voor. Bespreek de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduceren van het aantal false negatives door de threshold aan te passen\n",
    "#threshold verlagen!\n",
    "# reduceren van het aantal false negatives door de threshold aan te passen\n",
    "\n",
    "threshold = 0.21\n",
    "\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "preds = probs[:,1]\n",
    "\n",
    "preds2 = []\n",
    "\n",
    "\n",
    "\n",
    "for prediction in preds:\n",
    "\n",
    "    if  prediction >= threshold:\n",
    "\n",
    "        preds2.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        preds2.append(0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Origional:\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lowered threshold:\")\n",
    "\n",
    "print(classification_report(y_test, preds2))\n",
    "\n",
    "print(confusion_matrix(y_test,preds2))\n",
    "\n",
    "print(accuracy_score(y_test,preds2)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 2. Penguins\n",
    "\n",
    "\n",
    "De dataset `penguins.csv` bevat data van verschillende soorten pinguÃ¯ns. Deze dataset is origineel bedoeld om te kijken of het mogelijk is om te voorspellen tot welke soort een pinguÃ¯ns behoort aan de hand van de andere variabelen.\n",
    "\n",
    "<img src='penguins.jpg'>\n",
    "\n",
    "<br />\n",
    "\n",
    "| Variable | Beschrijving |\n",
    "| --- | --- | \n",
    "|studyName \t|De studie waar de data van de penguin oorspronkelijk vandaan komt. |\n",
    "|Sample Number|\tEen unieke ID die iedere penguin die in het onderzoek voorkomt krijgt.\n",
    "|Species |\t De soorten penguins die voorkomen in de dataset.|\n",
    "|Island | Het eiland waar de penguin geobserveerd werd.|\n",
    "|Clutch Completion | Of er minstens 1 eitje uit het nest uitgekomen is.|\n",
    "|Culmen Length (mm) |\tDe lengte van de snavel in millimeter. |\n",
    "|Culmen Depth (mm) | De diepte van de snavel in millimeter. |\n",
    "|Flipper Length (mm)  \t| De lengte van de vin in millimeter. |\n",
    "|Body Mass (g) | Het gewicht van de penguin in gram. |\n",
    "|Sex | Het geslacht (binair: 'FEMALE' - vrouw or 'MALE' - man)|\n",
    "|Comments | Specifieke commentaar die bij een bepaalde penguin hoort.|\n",
    "\n",
    "<br />   \n",
    "lees de dataset in en toon de eerste 7 rijen.  <br />   \n",
    "De kolom comments heeft amper data, deze kolom mag uit de dataset verwijdert worden.  <br />   \n",
    "Gebruik listwise deletion bij de overige ontbrekende waarden. Is de dataset gebalanceerd? Maw, zijn er evenveel penguins per soort?  <br />   \n",
    "Bouw een logistic regression model dat zo accuraat mogelijk de penguinsoort kan bepalen. Hierbij pas je alle overige preprocessing stappen toe die je nodig acht. Het is ook toegestaann om features bij te maken of weg te laten.\n",
    "<br />   \n",
    "Schrijf jouw conclusies op met betrekking tot het finaal bekomen model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('TestData2.csv')\n",
    "print('Dimensie van de dataset:',dataset.shape)\n",
    "dataset.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uitwerking van de opdracht: \n",
    "\n",
    "#comments kolom verwijderen\n",
    "# verwijder kollomen die niet relevant zijn met model (id's,types)\n",
    "dataset.drop(['PartitionKey','RowKey','Timestamp','RackRow'],axis=1,inplace=True)\n",
    "dataset.drop('RackRow@type',axis=1,inplace=True)\n",
    "dataset.drop('Label',axis=1,inplace=True)\n",
    "dataset.drop('Label@type',axis=1,inplace=True)\n",
    "\n",
    "# verwijder kollomen weight \n",
    "dataset.drop(['WeightPre','WeightPre@type','WeightPost','WeightPost@type', 'WeightDiff','WeightDiff@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#verwijder kollomen distance\n",
    "dataset.drop(['DistMinH@type','DistMaxH@type','DistAvgH@type','DistMinL@type', 'DistMaxL@type','DistAvgL@type', 'DistTime@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "# dataset = pd.concat([dataset,pd.get_dummies(dataset['RackRow'], prefix='RackRow')],axis=1)\n",
    "# dataset.drop(['RackRow'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van 'kant_krat_links' kolom op basis van DistAvgL\n",
    "# dataset.insert(0,'kant_krat_links', dataset['DistAvgL'])\n",
    "\n",
    "# #DistAvgL waarden\n",
    "\n",
    "# dataset['kant_krat_links'].values[dataset['DistAvgL'] < 20] = 0\n",
    "# dataset['kant_krat_links'].values[dataset['DistAvgL'] >= 20] = 1\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"DistAvgL\")\n",
    "plt.title('DistAvgL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsporen van ontbrekende waarden\n",
    "\n",
    "missing_values_count = dataset.isnull().sum()\n",
    "print(missing_values_count)\n",
    "msno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "\n",
    "dataset.corr()\n",
    "\n",
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['DistAvgL'].values\n",
    "X = dataset.drop(['DistAvgL'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "#1 lijst met 333 waarden, 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.90, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "\n",
    "# Om conversion warning te vermijden:\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "\n",
    "\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e4, solver='lbfgs') # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "                                                # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 2\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.1,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2- score op trainingsets: 0.89 en 0.75 graad 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 3.  Star Wars\n",
    "\n",
    "Train een logistic regression classifier aan de hand van de dataset 'StarWars.csv') om te voorspellen of iemand al dan niet een Star Wars fan is.\n",
    "Gebruik one-hot encondig waar nodig. Zorg ervoor dat de test set uit minstens 200 samples bestaat.\n",
    "Evalueer de getrainde classifier via de geziene metrics en bespreek de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('StarWars.csv')\n",
    "dataset.head(35)\n",
    "\n",
    "# we merken op dat rij 19 en 24 allemaal nullen bevat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "           square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding! (for loop?)\n",
    "\n",
    "#Have you seen any of the 6 films in the Star Wars franchise? kolom verwijderen en omzetten naar ..yes and ..no\n",
    "\n",
    "#omzetten/features toevoegen\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Have you seen any of the 6 films in the Star Wars franchise?'], prefix='Have you seen any of the 6 films in the Star Wars franchise?')],axis=1)\n",
    "#originele kolom verwijderen\n",
    "dataset.drop(['Have you seen any of the 6 films in the Star Wars franchise?'],axis=1, inplace=True)\n",
    "\n",
    "dataset.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we verwijderen rij 19 en 24  van kolom have you..No omdat ze daar 1 zijn\n",
    "dataset.drop(dataset.loc[dataset['Have you seen any of the 6 films in the Star Wars franchise?_No']==1].index, inplace=True)\n",
    "dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding toepassen op de overige kolommen\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#one-hot encoden van LIJST Features\n",
    "datasets_encode_list = ['Han Solo','Luke Skywalker','Princess Leia Organa','Anakin Skywalker',\n",
    "                        'Obi Wan Kenobi','Emperor Palpatine','Darth Vader','Lando Calrissian',\n",
    "                       'Boba Fett','C-3P0','Jar Jar Binks','Padme Amidala','Yoda',\n",
    "                        'Are you familiar with the Expanded Universe?',\n",
    "                        'Do you consider yourself to be a fan of the Expanded Universe?','Gender','Education',\n",
    "                        'phantom menace seen','attack of the clones seen','revenge of the sith seen','a new hope seen',\n",
    "                        'empire strikes back seen','return of the jedi seen','Location','StarWars fan','R2 D2',\n",
    "                        'Which character shot first?','Age'\n",
    "                       ]\n",
    "\n",
    "oude_datasets = dataset\n",
    "for column in datasets_encode_list:\n",
    "    dataset = pd.concat([dataset,pd.get_dummies(dataset[column],prefix=column)],axis=1)\n",
    "    oude_datasets = dataset.drop([column],axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "# # Han Solo omzetten\n",
    "# dataset = pd.concat([dataset,pd.get_dummies(dataset['Han Solo'], prefix='Han Solo')],axis=1)\n",
    "# #originele kolom verwijderen\n",
    "# dataset.drop(['Han Solo'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"StarWars fan_Yes\")\n",
    "plt.title('StarWars fan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['StarWars fan_Yes'].values\n",
    "X = dataset.drop(['StarWars fan_Yes'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 600 waarden, 130 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen/opdelen in training set en test set (hier minstens 200 training sample)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e2, solver='lbfgs') # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "                                                # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 1\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.0001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.001,tol=0.001,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Op beide trainingsets 0.99 en 0.99\n",
    "#AUC = 1.00 wat betekenet dat men perfect de klassen kan onderscheiden\n",
    "#Bij het wijzigen van C-parameter schommeling van ~0.1 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 4. Menselijke activiteit\n",
    "\n",
    "\n",
    "De dataset 'activiteit.csv' bevat meetgegevens die van 30 personen via een smartphone werden afgenomen. Deze meetwaarden zijn onderandere afkomstig van een accelerometer en een gyroscoop die in de smartphone zijn ingebouwd.\n",
    "De bedoeling is om om basis van deze meetwaarden de activiteit van de persoon zo nauwkeurig mogelijk te kunnen inschatten.\n",
    "Er zijn 6 verschillende klasses.\n",
    "\n",
    "\n",
    "Bepaal de 6 verschillende klasses en onderzoek meteen of de dataset gebalanceerd is (gelijkmatige verdeling van de verschillende klasses).\n",
    "Bouw een logistic regression model dat zo accuraat mogelijk de activiteit van de persoon kan bepalen. Hierbij pas je alle nodige preprocessing stappen toe je nodig acht.\n",
    "Het is ook toegestaann om features bij te maken of weg te laten. \n",
    "\n",
    "Schrijf jouw conclusies op met betrekking tot het finaal bekomen model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('activiteit.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking opdracht menselijke activiteit\n",
    "sns.countplot(data=dataset,x='Activity')\n",
    "plt.title('Countplot activity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "\n",
    "#dataset.corr()\n",
    "\n",
    "# Visualiseer de onderlinge correlatiecoÃ«fficiÃ«nten\n",
    "#f, ax = plt.subplots(figsize=(12, 10))\n",
    "#corr = dataset.corr()\n",
    "#sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "#            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistische kerngetallen\n",
    "#dataset.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot-encoding toepassen omdat ik strings moet omzetten naar getallen\n",
    "\n",
    "#Species omzetten\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Activity'], prefix='Activity')],axis=1)\n",
    "dataset.drop(['Activity'],axis=1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsporen van ontbrekende waarden\n",
    "\n",
    "missing_values_count = dataset.isnull().sum()\n",
    "print(missing_values_count)\n",
    "msno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "y = dataset['Activity_STANDING'].values\n",
    "X = dataset.drop(['Activity_STANDING'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 303 waarden, 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een logistic regression classifier\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e3, solver='lbfgs') # C= Inverse of regularization strength;\n",
    "                                                # must be a positive float. Like in support vector machines,\n",
    "                                                # smaller values specify stronger regularization.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print('coefficiÃ«nten: ',logreg.coef_)\n",
    "print('intercept:',logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testen van de logistic regression classifier\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability prediciton van ROC\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toevoegen van extra features\n",
    "# Modeloptimalisatie en Hyperparameter tuning\n",
    "# Automatisch toevoegen van hogere orde features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Aanmaken van de hogere orde features\n",
    "graad = 1\n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print('dimensie van X_train_poly: ',X_train_poly.shape)\n",
    "print('dimensie van X_test_poly: ',X_test_poly.shape)\n",
    "\n",
    "#scalen (optioneel?)\n",
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "\n",
    "X_train_poly = scaler_poly.transform(X_train_poly)\n",
    "X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "\n",
    "# met L2 regularisatie via Ridge regression\n",
    "lregmodel_poly = Ridge(alpha=20,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)\n",
    "\n",
    "print('R2 score op test set via L2: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "# R2 -score via L2 op de trainingset\n",
    "print('R2 score op training set via L2: ',lregmodel_poly.score(X_train_poly,y_train))\n",
    "\n",
    "\n",
    "# met L1 regularisatie via Lasso regression\n",
    "lregmodel_poly = Lasso(alpha=0.1,tol=0.01,fit_intercept=True)\n",
    "lregmodel_poly.fit(X_train_poly,y_train)      \n",
    "  \n",
    "      \n",
    "print('R2 score op test set via L1: ',lregmodel_poly.score(X_test_poly,y_test))\n",
    "  \n",
    "# R2 -score via L1 op de trainingset\n",
    "print('R2 score op training set via L1: ',lregmodel_poly.score(X_train_poly,y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 score op trainingsets 0.99 en 0.30(?)\n",
    "#Bij het wijzigen van C-parameter enkel verschil van accuracy (~0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
