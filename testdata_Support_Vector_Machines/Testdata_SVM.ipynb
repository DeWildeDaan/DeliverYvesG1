{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht Support Vector Machines & Hyperparametertuning\n",
    "\n",
    "Support Vector Machine zijn ondanks hun leeftijd nog altijd populair en heel frequent gebruikte ML algoritmes. Ze zijn bijzonder veelzijdig en kunnen ingezet worden bij zowel classificatieproblemen als regressieproblemen en zelfs bij het opsporen van uitschieters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "#bij metrics error:\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "#svm\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kankerdetectie\n",
    "\n",
    "Train een model om te voorspellen of een bepaalde tumor goedaardig (benign) of kwaadaardig (malignant) is. Gebruik daarvoor de dataset 'cancer.csv'\n",
    "\n",
    "Baseer je op de methodieken uit voorgaande opdrachten om tot een zo goed mogelijk resultaat te komen. Bespreek telkens de gemaakte keuzes en resultaten en kom tot een duidelijk besluit.\n",
    "\n",
    "Tip: een classifier kan enkel maar getraind worden met numerieke waarden. Vervang daarom bij de feature diagnose de twee klasses die voorkomen door 0 en 1, waarbij 0 staat voor goedaardig en 1 voor kwaadaardig.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartitionKey</th>\n",
       "      <th>RowKey</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>RackRow</th>\n",
       "      <th>RackRow@type</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label@type</th>\n",
       "      <th>WeightPre</th>\n",
       "      <th>WeightPre@type</th>\n",
       "      <th>WeightPost</th>\n",
       "      <th>WeightPost@type</th>\n",
       "      <th>WeightDiff</th>\n",
       "      <th>WeightDiff@type</th>\n",
       "      <th>DistMinH</th>\n",
       "      <th>DistMinH@type</th>\n",
       "      <th>DistMaxH</th>\n",
       "      <th>DistMaxH@type</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistAvgH@type</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMinL@type</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistMaxL@type</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistAvgL@type</th>\n",
       "      <th>DistTime</th>\n",
       "      <th>DistTime@type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>06e05b50-bcbf-4fad-a713-c19975ef4b42</td>\n",
       "      <td>2022-05-25T13:16:47.9637282Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>3</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>28</td>\n",
       "      <td>Int32</td>\n",
       "      <td>27</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>28</td>\n",
       "      <td>Int32</td>\n",
       "      <td>207</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>0cffb11c-0506-4d8d-8cad-7f2d00053380</td>\n",
       "      <td>2022-05-25T13:15:19.5884474Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>32</td>\n",
       "      <td>Int32</td>\n",
       "      <td>34</td>\n",
       "      <td>Int32</td>\n",
       "      <td>33</td>\n",
       "      <td>Int32</td>\n",
       "      <td>32</td>\n",
       "      <td>Int32</td>\n",
       "      <td>34</td>\n",
       "      <td>Int32</td>\n",
       "      <td>33</td>\n",
       "      <td>Int32</td>\n",
       "      <td>1136</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>11090373-a998-47a1-b8c3-807b4c036d53</td>\n",
       "      <td>2022-05-25T13:17:16.801118Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>6</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>9</td>\n",
       "      <td>Int32</td>\n",
       "      <td>10</td>\n",
       "      <td>Int32</td>\n",
       "      <td>9</td>\n",
       "      <td>Int32</td>\n",
       "      <td>9</td>\n",
       "      <td>Int32</td>\n",
       "      <td>15</td>\n",
       "      <td>Int32</td>\n",
       "      <td>11</td>\n",
       "      <td>Int32</td>\n",
       "      <td>513</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>13f3867e-2b06-43a9-8843-e3f5245cf925</td>\n",
       "      <td>2022-05-25T13:20:12.9485555Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>21</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>30</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>30</td>\n",
       "      <td>Int32</td>\n",
       "      <td>29</td>\n",
       "      <td>Int32</td>\n",
       "      <td>765</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F0:08:D1:C8:A7:34</td>\n",
       "      <td>275027a4-b73f-484f-916b-ba69df4b65c4</td>\n",
       "      <td>2022-05-25T13:21:42.5068964Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Int32</td>\n",
       "      <td>5</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>0</td>\n",
       "      <td>Int32</td>\n",
       "      <td>12</td>\n",
       "      <td>Int32</td>\n",
       "      <td>16</td>\n",
       "      <td>Int32</td>\n",
       "      <td>14</td>\n",
       "      <td>Int32</td>\n",
       "      <td>12</td>\n",
       "      <td>Int32</td>\n",
       "      <td>16</td>\n",
       "      <td>Int32</td>\n",
       "      <td>14</td>\n",
       "      <td>Int32</td>\n",
       "      <td>1135</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PartitionKey                                RowKey  \\\n",
       "0  F0:08:D1:C8:A7:34  06e05b50-bcbf-4fad-a713-c19975ef4b42   \n",
       "1  F0:08:D1:C8:A7:34  0cffb11c-0506-4d8d-8cad-7f2d00053380   \n",
       "2  F0:08:D1:C8:A7:34  11090373-a998-47a1-b8c3-807b4c036d53   \n",
       "3  F0:08:D1:C8:A7:34  13f3867e-2b06-43a9-8843-e3f5245cf925   \n",
       "4  F0:08:D1:C8:A7:34  275027a4-b73f-484f-916b-ba69df4b65c4   \n",
       "\n",
       "                      Timestamp  RackRow RackRow@type  Label Label@type  \\\n",
       "0  2022-05-25T13:16:47.9637282Z        2        Int32      3      Int32   \n",
       "1  2022-05-25T13:15:19.5884474Z        2        Int32      2      Int32   \n",
       "2   2022-05-25T13:17:16.801118Z        2        Int32      6      Int32   \n",
       "3  2022-05-25T13:20:12.9485555Z        2        Int32     21      Int32   \n",
       "4  2022-05-25T13:21:42.5068964Z        2        Int32      5      Int32   \n",
       "\n",
       "   WeightPre WeightPre@type  WeightPost WeightPost@type  WeightDiff  \\\n",
       "0          0          Int32           0           Int32           0   \n",
       "1          0          Int32           0           Int32           0   \n",
       "2          0          Int32           0           Int32           0   \n",
       "3          0          Int32           0           Int32           0   \n",
       "4          0          Int32           0           Int32           0   \n",
       "\n",
       "  WeightDiff@type  DistMinH DistMinH@type  DistMaxH DistMaxH@type  DistAvgH  \\\n",
       "0           Int32        27         Int32        29         Int32        28   \n",
       "1           Int32        32         Int32        34         Int32        33   \n",
       "2           Int32         9         Int32        10         Int32         9   \n",
       "3           Int32        29         Int32        30         Int32        29   \n",
       "4           Int32        12         Int32        16         Int32        14   \n",
       "\n",
       "  DistAvgH@type  DistMinL DistMinL@type  DistMaxL DistMaxL@type  DistAvgL  \\\n",
       "0         Int32        27         Int32        29         Int32        28   \n",
       "1         Int32        32         Int32        34         Int32        33   \n",
       "2         Int32         9         Int32        15         Int32        11   \n",
       "3         Int32        29         Int32        30         Int32        29   \n",
       "4         Int32        12         Int32        16         Int32        14   \n",
       "\n",
       "  DistAvgL@type  DistTime DistTime@type  \n",
       "0         Int32       207         Int32  \n",
       "1         Int32      1136         Int32  \n",
       "2         Int32       513         Int32  \n",
       "3         Int32       765         Int32  \n",
       "4         Int32      1135         Int32  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inlezen van de dataset\n",
    "\n",
    "dataset = pd.read_csv('TestData.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistMinH</th>\n",
       "      <th>DistMaxH</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DistMinH  DistMaxH  DistAvgH  DistMinL  DistMaxL  DistAvgL  DistTime\n",
       "0        27        29        28        27        29        28       207\n",
       "1        32        34        33        32        34        33      1136\n",
       "2         9        10         9         9        15        11       513\n",
       "3        29        30        29        29        30        29       765\n",
       "4        12        16        14        12        16        14      1135\n",
       "5         9        12        10         9        12        10       574\n",
       "6        27        29        27        27        29        27       393\n",
       "7        37        37        37        37        37        37        25\n",
       "8        32        35        33        32        35        33       584\n",
       "9        39        41        40        39        41        40       766"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verwijder kollomen die niet relevant zijn met model (id's,types)\n",
    "dataset.drop(['PartitionKey','Timestamp','RackRow','RowKey'],axis=1,inplace=True)\n",
    "dataset.drop('RackRow@type',axis=1,inplace=True)\n",
    "dataset.drop('Label',axis=1,inplace=True)\n",
    "dataset.drop('Label@type',axis=1,inplace=True)\n",
    "\n",
    "# verwijder kollomen weight \n",
    "dataset.drop(['WeightPre','WeightPre@type','WeightPost','WeightPost@type', 'WeightDiff','WeightDiff@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#verwijder kollomen distance\n",
    "dataset.drop(['DistMinH@type','DistMaxH@type','DistAvgH@type','DistMinL@type', 'DistMaxL@type','DistAvgL@type', 'DistTime@type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "# dataset = pd.concat([dataset,pd.get_dummies(dataset['RowKey'], prefix='RowKey')],axis=1)\n",
    "# dataset.drop(['RowKey'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kant_krat_links</th>\n",
       "      <th>DistMinH</th>\n",
       "      <th>DistMaxH</th>\n",
       "      <th>DistAvgH</th>\n",
       "      <th>DistMinL</th>\n",
       "      <th>DistMaxL</th>\n",
       "      <th>DistAvgL</th>\n",
       "      <th>DistTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kant_krat_links  DistMinH  DistMaxH  DistAvgH  DistMinL  DistMaxL  \\\n",
       "0                1        27        29        28        27        29   \n",
       "1                1        32        34        33        32        34   \n",
       "2                0         9        10         9         9        15   \n",
       "3                1        29        30        29        29        30   \n",
       "4                0        12        16        14        12        16   \n",
       "5                0         9        12        10         9        12   \n",
       "6                1        27        29        27        27        29   \n",
       "7                1        37        37        37        37        37   \n",
       "8                1        32        35        33        32        35   \n",
       "9                1        39        41        40        39        41   \n",
       "\n",
       "   DistAvgL  DistTime  \n",
       "0        28       207  \n",
       "1        33      1136  \n",
       "2        11       513  \n",
       "3        29       765  \n",
       "4        14      1135  \n",
       "5        10       574  \n",
       "6        27       393  \n",
       "7        37        25  \n",
       "8        33       584  \n",
       "9        40       766  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toevoegen van 'kant_krat_links' kolom op basis van DistAvgL\n",
    "dataset.insert(0,'kant_krat_links', dataset['DistAvgL'])\n",
    "\n",
    "#DistAvgL waarden\n",
    "\n",
    "dataset['kant_krat_links'].values[dataset['DistAvgL'] < 20] = 0\n",
    "dataset['kant_krat_links'].values[dataset['DistAvgL'] >= 20] = 1\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'diagnosis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Bepaal de mate van gebalanceerdheid van de dataset. Je kan hiervoor gebruik maken van de Seaborn countplot\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Bepaal ook de verhouding van het aantal samples van de twee verschillende klasses.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# gebalanceerdheid controleren\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiagnosis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountplot diagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass the following variable\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mkeyword arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:3598\u001b[0m, in \u001b[0;36mcountplot\u001b[1;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, dodge, ax, **kwargs)\u001b[0m\n\u001b[0;32m   3595\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass values for both `x` and `y`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3598\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_CountPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3601\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3602\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\n\u001b[0;32m   3603\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3605\u001b[0m plotter\u001b[38;5;241m.\u001b[39mvalue_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:1584\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[0;32m   1580\u001b[0m              estimator, ci, n_boot, units, seed,\n\u001b[0;32m   1581\u001b[0m              orient, color, palette, saturation, errcolor,\n\u001b[0;32m   1582\u001b[0m              errwidth, capsize, dodge):\n\u001b[0;32m   1583\u001b[0m     \u001b[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1584\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m                             \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[0;32m   1587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_statistic(estimator, ci, n_boot, seed)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:153\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(var, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    152\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret input \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(var)\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Figure out the plotting orientation\u001b[39;00m\n\u001b[0;32m    156\u001b[0m orient \u001b[38;5;241m=\u001b[39m infer_orient(\n\u001b[0;32m    157\u001b[0m     x, y, orient, require_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_numeric\n\u001b[0;32m    158\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret input 'diagnosis'"
     ]
    }
   ],
   "source": [
    "# Bepaal de mate van gebalanceerdheid van de dataset. Je kan hiervoor gebruik maken van de Seaborn countplot\n",
    "# Bepaal ook de verhouding van het aantal samples van de twee verschillende klasses.\n",
    "\n",
    "\n",
    "\n",
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"kant_krat_links\")\n",
    "plt.title('Countplot kant_krat_links')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "\n",
    "y = dataset['kant_krat_links'].values\n",
    "X = dataset.drop(['kant_krat_links'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 568 waarden, 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in training set en test set. Zorg ervoor dat er 150 samples in de test set zitten.\n",
    "\n",
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=150, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(f'testdata:',X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalisatie van de features\n",
    "\n",
    "# Om conversion warning te vermijden:\n",
    "\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "\n",
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "\n",
    "#scalen met MinMax?\n",
    "#scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train zowel een logistic regression model als een Support Vector Machine via cross-validation.\n",
    "\n",
    "#logistic regression (classweight balancing)\n",
    "\n",
    "\n",
    "#Wanneer het aantal features groot is ten opzichte van het aantal training samples\n",
    "\n",
    "model = LogisticRegression(C=1, solver='liblinear',class_weight='balanced')\n",
    "\n",
    "# Trainen van het model\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Testen van het model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n",
    "# ROC\n",
    "probs = model.predict_proba(X_test)\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# plot\n",
    "#import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (classweight balancing) \n",
    "#97 met MinMaxScaler, 98 met StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation \n",
    "\n",
    "from sklearn.model_selection import learning_curve \n",
    "\n",
    "# Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(C=10000),\n",
    "                                                        X_train, y_train,cv=5, scoring='accuracy',\n",
    "                                                        n_jobs=-1,train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"red\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color=\"blue\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling with SMOTE\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#X_resampled, y_resampled = SMOTE( k_neighbors=4, n_jobs=-1, m_neighbors=8).fit_resample(X_train, y_train)\n",
    "\n",
    "#print(y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with SMOTE\n",
    "\n",
    "#werkt niet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine/SVM (Lineair)\n",
    "\n",
    "SVMlinear = svm.SVC(kernel='linear',C=0.1, class_weight='balanced')\n",
    "SVMlinear.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM (lineair) model testen\n",
    "y_pred = SVMlinear.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM (Lineair)\n",
    "#Gridsearch: C = 0.1\n",
    "#98.67  C = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#model trainen\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000,10000, 100000]}                                       \n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20, # K = 20\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine/SVM (Met Kernel)\n",
    "SVMkernel = svm.SVC(kernel='rbf',C=2.492356691610501,gamma=0.03595203735958652, class_weight='balanced')\n",
    "#SVMkernel = svm.SVC(kernel='poly',C=1)\n",
    "SVMkernel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#SVM (met Kernel) model testen\n",
    "y_pred = SVMkernel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM met Kernel\n",
    "#93.33 bij  C = 0.1 \n",
    "\n",
    "#Gridsearch: C = 10, gamma = 0.01\n",
    "#94.0  C = 10\n",
    "#95.33 C = 10 gamma = 0.01\n",
    "\n",
    "#Randomsearch: C = 2.492356691610501, gamma = 0.03595203735958652\n",
    "#95.33  C = 2.492356691610501, gamma = 0.03595203735958652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Gridsearch op SVM met Kernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.learning_curve import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "model = SVC()\n",
    "paramaters = [ \n",
    "        {'kernel': ['linear'], 'C': np.linspace(1,20,100)},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2]},\n",
    "        {'kernel': ['poly'], 'C':[1, 10]} ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10, # K\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 4)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een SVM via random search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "\n",
    "model = SVC(probability=True)\n",
    "parameters = {'kernel': ['linear','rbf','poly'],\n",
    "              'C': uniform(0.01, 20), # haal C uit een random uniform distribution\n",
    "              'gamma': uniform(0.001, 0.2)}\n",
    "\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n",
    "\n",
    "# ROC\n",
    "probs = grid_search.predict_proba(X_test)\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# plot\n",
    "#import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve \n",
    "\n",
    "# Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(SVC(kernel='linear',C=1),\n",
    "                                                        X_train, y_train,cv=5, scoring='accuracy',\n",
    "                                                        n_jobs=-1,train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"red\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color=\"blue\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train zowel een logistic regression model als een Support Vector Machine via cross-validation.\n",
    "\n",
    "Gebruik daarvoor zowel grid search, random search en eventueel Bayes optimization (indien werkende) om op zoek te gaan naar de beste hyperparameters: C-waarde, class_weight, etc. Meer info: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html. \n",
    "\n",
    "De Bayes optimzation uit de scikit-optimize (skopt) lijkt niet altijd meer te werken. Daarom kan je best gebruik maken van de optimzer te vinden op https://github.com/fmfn/BayesianOptimization.\n",
    "Installatie hiervan kan via volgend commando in de command line:\n",
    "\n",
    "`pip3 install git+https://github.com/darenr/scikit-optimize`\n",
    "Indien deze BayesOptimization problemen geeft mag je deze stap van de opdracht overslaan.\n",
    "    \n",
    "Varieer bij K-fold cross-validation de waarde van K. Bespreek de resultaten.\n",
    "Test de bekomen modellen op de test set. Welke search techniek geniet jouw voorkeur en waarom?\n",
    "Heeft het zin om de featureset uit te breiden met polynomial features? Test dit. http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "Bespreek telkens de bekomen resultaten in termen van de classificatiemetrics. Ga ook na of de modellen last lijken te hebben van niet-gebalanceerdheid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Logistic regression(classweight-balancing): 98\n",
    "#SVM (Linear/zonder kernel): 98.67\n",
    "#SVM (met kernel): 95,33\n",
    "\n",
    "\n",
    "# SVM met kernel lijkt last te hebben van niet-gebalanceerdheid\n",
    "#aangezien het ook de grootste verschil heeft tussen zijn F1 score (0.97 en 0.93 (0.4 verschil))\n",
    "#bij de andere modellen verschilt de onderlinge F1 score met 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stel dat de vereiste aan het model wordt gesteld dat de recall bij kwaadaardige tumoren minstens 99% moet zijn met behoud van een zo hoog mogelijk accuraatheid.\n",
    "Onderzoek onderstaande mogelijkheden om aan deze vereiste te voldoen:\n",
    "- Classweight balancing. Kijk eerst of class_weight='balanced' voldoende is. Indien niet, geeft zelf classweights mee met het model zodat toch aan de vereisten kan voldoen worden. Zowel logistic regression als Support Vector Machines ondersteunen deze classweight balancing.\n",
    "- Onderzoek of undersampling/oversampling (via SMOTE) gebruikt kan worden om de vereiste te halen. Vermoedelijk moet je hiervoor nog de imbalanced-learn library installeren via `pip3 install imbalanced-learn`\n",
    "\n",
    "- Threshold moving: verschuif de classificatie-threshold in het voordeel van de klasse kwaadaardig. Gebruik hiervoor enkel logistic regression. Gebruik de predict_proba values en de zelfgekozen threshold om te bepalen tot welke klasse een sample behoort. Kies deze threshold zorgvuldig zodat de recall voor de klasse kwaadaardig minstens 99% op de test set bedraagt maar de totale accuraatheid zo groot mogelijk blijft.\n",
    "\n",
    "Bespreek de bekomen resultaten. Welke methode geniet hier jouw voorkeur en waarom?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking\n",
    "# add classweight-balancing\n",
    "#bij SVM (met kernel) stijgt het van 95.33 naar 96.0 en recall van (1.00,0.86 -> 0.99,0.90)\n",
    "#bij SVM lineair geen effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vraag 2. Patient survival prediction\n",
    "\n",
    "De dataset `Patient_survival.csv` bevat gegevens over patienten in die opgenomen zijn in de intensive care unit (ICU) in verschillende ziekenhuizen. De kolom `hospital_death` geeft weer of een patient al dan niet gestorven is in het ziekenhuis.\n",
    "\n",
    "De features zijn de volgende:\n",
    "<br />\n",
    "\n",
    "| Variable | Beschrijving |\n",
    "| --- | --- | \n",
    "|encounter_id|Unique identifier associated with a patient unit stay. |\n",
    "|patient_id|Unique identifier associated with a patient.|\n",
    "|hospital_id |Unique identifier associated with a hospital. |\n",
    "|age |The age of the patient on unit admission.|\n",
    "|bmi |The body mass index of the person on unit admission.|\n",
    "|elective_surgery |Whether the patient was admitted to the hospital for an elective surgical operation.|\n",
    "|gender | Sex of the patient.|\n",
    "|height| The height of the person on unit admission.|\n",
    "|icu_id|A unique identifier for the unit to which the patient was admitted .|\n",
    "|pre_icu_los_days|The length of stay of the patient between hospital admission and unit admission.|\n",
    "|weight|The weight (body mass) of the person on unit admission.|\n",
    "|apache_3j_diagnosis | The APACHE III-J sub-diagnosis code which best describes the reason for the ICU admission.|\n",
    "|apache_post_operative|The APACHE operative status; 1 for post-operative, 0 for non-operative. |\n",
    "|arf_apache|Whether the patient had acute renal failure during the first 24 hours of their unit stay, defined as a 24 hour urine output <410ml, creatinine >=133 micromol/L and no chronic dialysis.|\n",
    "|gcs_eyes_apache|The eye opening component of the Glasgow Coma Scale measured during the first 24 hours which results in the highest APACHE III score.|\n",
    "|gcs_motor_apache| The motor component of the Glasgow Coma Scale measured during the first 24 hours which results in the highest APACHE III score .|\n",
    "|gcs_unable_apache|Whether the Glasgow Coma Scale was unable to be assessed due to patient sedation|\n",
    "|gcs_verbal_apache|The verbal component of the Glasgow Coma Scale measured during the first 24 hours which results in the highest APACHE III score |\n",
    "|heart_rate_apache|The heart rate measured during the first 24 hours which results in the highest APACHE III score.|\n",
    "|intubated_apache| Whether the patient was intubated at the time of the highest scoring arterial blood gas used in the oxygenation score.|\n",
    "|map_apache|The mean arterial pressure measured during the first 24 hours which results in the highest APACHE III score|\n",
    "|resprate_apache|The respiratory rate measured during the first 24 hours which results in the highest APACHE III score|\n",
    "|temp_apache|The temperature measured during the first 24 hours which results in the highest APACHE III score|\n",
    "|ventilated_apache|Whether the patient was invasively ventilated at the time of the highest scoring arterial blood gas using the oxygenation scoring algorithm, including any mode of positive pressure ventilation delivered through a circuit attached to an endo-tracheal tube or tracheostomy.|\n",
    "|d1_diasbp_max|The patient's highest diastolic blood pressure during the first 24 hours of their unit stay, either non-invasively or invasively measured.|\n",
    "|d1_diasbp_min|The patient's lowest diastolic blood pressure during the first 24 hours of their unit stay, either non-invasively or invasively measured|\n",
    "|d1_diasbp_noninvasive_max|The patient's highest diastolic blood pressure during the first 24 hours of their unit stay, non-invasively measured.|\n",
    "|d1_diasbp_noninvasive_min|The patient's lowest diastolic blood pressure during the first 24 hours of their unit stay, non-invasively measured.|\n",
    "|d1_heartrate_max|The patient's highest heart rate during the first 24 hours of their unit stay|\n",
    "|d1_heartrate_min|The patient's lowest heart rate during the first 24 hours of their unit stay|\n",
    "|d1_mbp_max|The patient's highest mean blood pressure during the first 24 hours of their unit stay, either non-invasively or invasively measured|\n",
    "|d1_mbp_min|The patient's lowest mean blood pressure during the first 24 hours of their unit stay, either non-invasively or invasively measured|\n",
    "|d1_mbp_noninvasive_max | The patient's highest mean blood pressure during the first 24 hours of their unit stay, non-invasively measured|\n",
    "|d1_mbp_noninvasive_min | The patient's lowest mean blood pressure during the first 24 hours of their unit stay, non-invasively measured|\n",
    "|d1_resprate_max|The patient's highest respiratory rate during the first 24 hours of their unit stay|\n",
    "|d1_resprate_min|The patient's lowest respiratory rate during the first 24 hours of their unit stay|\n",
    "|d1_spo2_max|The patient's highest peripheral oxygen saturation during the first 24 hours of their unit stay|\n",
    "|d1_spo2_min|The patient's lowest peripheral oxygen saturation during the first 24 hours of their unit stay|\n",
    "|d1_sysbp_max|The patient's highest systolic blood pressure during the first 24 hours of their unit stay, either non-invasively or invasively measured|\n",
    "|d1_sysbp_min|The patient's lowest systolic blood pressure during the first 24 hours of their unit stay, either non-invasively or invasively measured|\n",
    "|d1_sysbp_noninvasive_max|The patient's highest systolic blood pressure during the first 24 hours of their unit stay, invasively measured|\n",
    "|d1_sysbp_noninvasive_min|The patient's lowest systolic blood pressure during the first 24 hours of their unit stay, invasively measured\n",
    "|d1_temp_max|The patient's highest core temperature during the first 24 hours of their unit stay, invasively measured\n",
    "|d1_temp_min|The patient's lowest core temperature during the first 24 hours of their unit stay\n",
    "|h1_diasbp_max|The patient's highest diastolic blood pressure during the first hour of their unit stay, either non-invasively or invasively measured|\n",
    "|h1_diasbp_min|The patient's lowest diastolic blood pressure during the first hour of their unit stay, either non-invasively or invasively measured|\n",
    "|h1_diasbp_noninvasive_max|The patient's highest diastolic blood pressure during the first hour of their unit stay, invasively measured|\n",
    "|h1_diasbp_noninvasive_min|The patient's lowest diastolic blood pressure during the first hour of their unit stay, invasively measured|\n",
    "|h1_heartrate_max|The patient's highest heart rate during the first hour of their unit stay|\n",
    "|h1_heartrate_min|The patient's lowest heart rate during the first hour of their unit stay|\n",
    "|h1_mbp_max|The patient's highest mean blood pressure during the first hour of their unit stay, either non-invasively or invasively measured|\n",
    "|h1_mbp_min|The patient's lowest mean blood pressure during the first hour of their unit stay, either non-invasively or invasively measured|\n",
    "|h1_mbp_noninvasive_max|The patient's highest mean blood pressure during the first hour of their unit stay, non-invasively measured|\n",
    "|h1_mbp_noninvasive_min|The patient's lowest mean blood pressure during the first hour of their unit stay, non-invasively measured|\n",
    "|h1_resprate_max|The patient's highest respiratory rate during the first hour of their unit stay|\n",
    "|h1_resprate_min|The patient's lowest respiratory rate during the first hour of their unit stay|\n",
    "|h1_spo2_max|The patient's highest peripheral oxygen saturation during the first hour of their unit stay|\n",
    "|h1_spo2_min|The patient's lowest peripheral oxygen saturation during the first hour of their unit stay|\n",
    "|h1_sysbp_max|The patient's highest systolic blood pressure during the first hour of their unit stay, either non-invasively or invasively measured|\n",
    "|h1_sysbp_min|The patient's lowest systolic blood pressure during the first hour of their unit stay, either non-invasively or invasively measured|\n",
    "|h1_sysbp_noninvasive_max|The patient's highest systolic blood pressure during the first hour of their unit stay, non-invasively measured|\n",
    "|h1_sysbp_noninvasive_min|The patient's lowest systolic blood pressure during the first hour of their unit stay, non-invasively measured|\n",
    "|d1_glucose_max|The highest glucose concentration of the patient in their serum or plasma during the first 24 hours of their unit stay\n",
    "|d1_glucose_minThe lowest glucose concentration of the patient in their serum or plasma during the first 24 hours of their unit stay\n",
    "d1_potassium_max|The highest potassium concentration for the patient in their serum or plasma during the first 24 hours of their unit stay\n",
    "d1_potassium_min|The lowest potassium concentration for the patient in their serum or plasma during the first 24 hours of their unit stay\n",
    "apache_4a_hospital_death_prob|The APACHE IVa probabilistic prediction of in-hospital mortality for the patient which utilizes the APACHE III score and other covariates, including diagnosis.\n",
    "apache_4a_icu_death_prob|The APACHE IVa probabilistic prediction of in ICU mortality for the patient which utilizes the APACHE III score and other covariates, including diagnosis\n",
    "aids|Whether the patient has a definitive diagnosis of acquired immune deficiency syndrome (AIDS) (not HIV positive alone)\n",
    "|cirrhosis|Whether the patient has a history of heavy alcohol use with portal hypertension and varices, other causes of cirrhosis with evidence of portal hypertension and varices, or biopsy proven cirrhosis. This comorbidity does not apply to patients with a functioning liver transplant.\n",
    "diabetes_mellitus|Whether the patient has been diagnosed with diabetes, either juvenile or adult onset, which requires medication.\n",
    "hepatic_failure|Whether the patient has cirrhosis and additional complications including jaundice and ascites, upper GI bleeding, hepatic encephalopathy, or coma.\n",
    "immunosuppression|Whether the patient has their immune system suppressed within six months prior to ICU admission for any of the following reasons; radiation therapy, chemotherapy, use of non-cytotoxic immunosuppressive drugs, high dose steroids (at least 0.3 mg/kg/day of methylprednisolone or equivalent for at least 6 months).\n",
    "leukemia\n",
    "lymphoma|Whether the patient has been diagnosed with non-Hodgkin lymphoma.\n",
    "solid_tumor_with_metastasis|Whether the patient has been diagnosed with any solid tumor carcinoma (including malignant melanoma) which has evidence of metastasis.\n",
    "apache_3j_bodysystem|Admission diagnosis group for APACHE III\n",
    "Unnamed: 83|?\n",
    "hospital_death|Whether the patient died during this hospitalization \n",
    "|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "De bedoeling is om een zo classifier (logistic regression of SVM) te trainen die zo goed mogelijk kan voorspellen of een patient al dan niet zal sterven na opname in de ICU.\n",
    "\n",
    "Doorloop volgende stappen:\n",
    "\n",
    "- Contoleer de gebalanceerheid van de dataset. Wat is de verhouding van de twee klasses?\n",
    "- Verwijder er 'id'-featurs die verwijdert kunnen worden?\n",
    "- Zijn er overbodige features die verwijdert kunnen worden?\n",
    "- Verwijder rijen die ontbrekende waarden bevat.\n",
    "- Verander categorische variabelen naar numerieke variabelen. Dit kan door binaire categorien om te zetten naar 1/0 en door one-hot encoding toe te passen daar waar meerdere categorien aanwezig zijn.\n",
    "- Splits op in features en targets en vervolgens in een training set en test set. Zorg voor een test set met 20% van de samples. Scale de dataset.\n",
    "- Train een logistic regression model en SVM. Dit mag onmiddellijk via cross-validatie gebeuren.\n",
    "- Onderzoek in welke mate het model last heeft van de ongebalanceerdheid van de dataset.\n",
    "- Teken de ROC-curve. Kan je hieruit aflezen of de classifier al dan niet last heeft van niet-gebalanceerd.\n",
    "- Teken nu ook de Precision-Recall curve. Wat kan je hieruit besluiten?\n",
    "- De klant wil graag een model dat een macro_f1 score haalt op de test set die zo hoog mogelijk ligt (liefst hoger ligt dan 70%). Bekijk nu opnieuw de ROC-curve en de Precision-Recall curve. Wat kan je besluiten?\n",
    "- Onderzoek of je door het weglaten van bepaalde features betere resultaten haalt. \n",
    "\n",
    "### OPMERKING\n",
    "\n",
    "Omwille van de omvang de dataset kan het trainen van de modellen bijzonder intensief zijn. Daarom is het toegestaan om de training set (drastisch) te verkleinen.\n",
    "Het kan wel zijn dat de performantie van het model daalt wanneer je minder training dat gebruikt. In dat geval kan het zijn dat een macro_f1 score van 70% niet haalbaar is. Probeer dan een zo hoog mogelijke macro_f1 score te bekomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Patient_survival.csv')\n",
    "dataset.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uitwerking\n",
    "# gebalanceerdheid controleren\n",
    "sns.countplot(data=dataset, x=\"hospital_dead\")\n",
    "plt.title('Countplot hospital_deaths')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "#Corr=dataset[dataset.columns].corr() \n",
    "#sns.heatmap(Corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#nutteloze features verwijderen! #geen polynomial features anders gaat het crashen/vastzitten\n",
    "#dataset.dropna( axis=0,inplace=True)\n",
    "\n",
    "# kolom met alle waarde NaN verwijderen ('Unnamed: 86')\n",
    "dataset.dropna(how='all', axis=1,inplace=True)\n",
    "\n",
    "# M en F van 'gender' omzetten naar 0 en 1:\n",
    "dataset.gender.replace({'F':0,'M':1},inplace=True)\n",
    "\n",
    "#one-hot encoden 'apache_3j_bodysystem'\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['apache_3j_bodysystem'],prefix='apache_3j_bodysystem')],axis=1)\n",
    "#originele kolom verwijderen\n",
    "dataset.drop(['apache_3j_bodysystem'],axis=1, inplace=True)\n",
    "\n",
    "# rows met NaN verwijderen\n",
    "dataset.dropna(axis=0,inplace=True)\n",
    "\n",
    "dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verwijder de kolom encounter_id en patient_id omdat je er mag vanuit gaan dat deze geen invloed heeft op de overlevingskans\n",
    "#dataset.drop('icu_id',axis=1, inplace=True)\n",
    "#dataset.drop('patient_id',axis=1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in features en targets\n",
    "\n",
    "y = dataset['hospital_dead'].values\n",
    "X = dataset.drop(['hospital_dead'], axis = 1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#1 lijst met 568 waarden, 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in training set en test set. Zorg ervoor dat er 20% samples in de test set zitten.\n",
    "\n",
    "# Opsplitsen/opdelen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "#training set\n",
    "print(X_train.shape)\n",
    "\n",
    "#test set\n",
    "print(f'testdata:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalisatie van de features\n",
    "\n",
    "# Om conversion warning te vermijden:\n",
    "\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "\n",
    "# Normaliseren / scaling van de training set en de test set\n",
    "scaler = StandardScaler() #scalen\n",
    "\n",
    "#scalen met MinMax?\n",
    "#scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train zowel een logistic regression model als een Support Vector Machine via cross-validation.\n",
    "\n",
    "#logistic regression (classweight balancing)\n",
    "\n",
    "\n",
    "#Wanneer het aantal features groot is ten opzichte van het aantal training samples\n",
    "\n",
    "model = LogisticRegression(C=1, solver='liblinear',class_weight='balanced')\n",
    "\n",
    "# Trainen van het model\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Testen van het model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n",
    "# ROC\n",
    "probs = model.predict_proba(X_test)\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# plot\n",
    "#import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (classweight balancing) \n",
    "#80 met StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation \n",
    "\n",
    "from sklearn.model_selection import learning_curve \n",
    "\n",
    "# Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(C=10000),\n",
    "                                                        X_train, y_train,cv=5, scoring='accuracy',\n",
    "                                                        n_jobs=-1,train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"red\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color=\"blue\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine/SVM (Lineair)\n",
    "\n",
    "SVMlinear = svm.SVC(kernel='linear',C=1, class_weight='balanced')\n",
    "SVMlinear.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM (lineair) model testen\n",
    "y_pred = SVMlinear.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#model trainen\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000,10000, 100000]}                                       \n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20, # K = 20\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine/SVM (Met Kernel)\n",
    "SVMkernel = svm.SVC(kernel='rbf',C=0.01,gamma=0.01, class_weight='balanced')\n",
    "#SVMkernel = svm.SVC(kernel='poly',C=1)\n",
    "SVMkernel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SVM (met Kernel) model testen\n",
    "y_pred = SVMkernel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM met kernel en C,gamma= 0.1 ~ 18 accuracy\n",
    "#SVM met kernel en C,gamma = 0.01 ~ 76 accuracy\n",
    "#SVM met kernel en C,gamma = 0.001 ~  9 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een SVM via random search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "\n",
    "model = SVC(probability=True)\n",
    "parameters = {'kernel': ['linear','rbf','poly'],\n",
    "              'C': uniform(0.01, 20), # haal C uit een random uniform distribution\n",
    "              'gamma': uniform(0.001, 0.2)}\n",
    "\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n",
    "\n",
    "# ROC\n",
    "probs = grid_search.predict_proba(X_test)\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# plot\n",
    "#import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Gridsearch op SVM met Kernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.learning_curve import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "model = SVC()\n",
    "paramaters = [ \n",
    "        {'kernel': ['linear'], 'C': np.linspace(1,20,100)},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2]},\n",
    "        {'kernel': ['poly'], 'C':[1, 10]} ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 2, # K\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 4)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "700.85px",
    "left": "1759.33px",
    "right": "20px",
    "top": "145px",
    "width": "438px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
